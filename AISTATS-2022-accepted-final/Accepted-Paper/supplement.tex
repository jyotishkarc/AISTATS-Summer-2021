\documentclass[twoside]{article}

\usepackage{aistats2022}
% If your paper is accepted, change the options for the package
% aistats2022 as follows:
%
%\usepackage[accepted]{aistats2022}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.
\usepackage{tablefootnote}
\usepackage{adjustbox}
\usepackage{tcolorbox}
\usepackage{wrapfig}
\usepackage{mathtools}
\usepackage{centernot}
\usepackage{epsfig}
\usepackage{amssymb,amsmath}%showkeys}
\usepackage{enumerate}
\usepackage{verbatim}
%\usepackage{multirow}
\usepackage{multicol}
\usepackage[english]{babel}
\usepackage{float}
\usepackage{hyperref}
\usepackage{tabularx}
\hypersetup{
     colorlinks=true,
     linkcolor=blue,
     citecolor=blue,
     filecolor=blue,
     urlcolor=blue,
}
\usepackage{setspace}
\usepackage{mathrsfs}
\usepackage[skip=0pt]{caption}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\tvacomment#1{\vskip 2mm\boxit{\vskip 2mm{\color{blue}\bf \bf#1} {\color{magenta}\bf \bf -- TVA\vskip 2mm}}\vskip 2mm}
\def\mggcomment#1{\vskip 2mm\boxit{\vskip 2mm{\color{magenta}\bf \bf#1} {\color{black}\bf -- MGG\vskip 2mm}}\vskip 2mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\wt{\widetilde}
\def\diag{\hbox{diag}}
\def\wh{\widehat}
\def\AIC{\hbox{AIC}}
\def\BIC{\hbox{BIC}}
%- Makes the section title start with Appendix in the appendix environment
\newcommand{\Appendix}
{%\appendix
\def\thesection{Appendix~\Alph{section}}
%\def\thesubsection{\Alph{section}.\arabic{subsection}}
\def\thesubsection{A.\arabic{subsection}}
}
\def\diag{\hbox{diag}}
\def\log{\hbox{log}}
\def\bias{\hbox{bias}}
\def\Siuu{\boldSigma_{i,uu}}
\def\dfrac#1#2{{\displaystyle{#1\over#2}}}
\def\VS{{\vskip 3mm\noindent}}
\def\boxit#1{\vbox{\hrule\hbox{\vrule\kern6pt
          \vbox{\kern6pt#1\kern6pt}\kern6pt\vrule}\hrule}}
\def\refhg{\hangindent=20pt\hangafter=1}
\def\refmark{\par\vskip 2mm\noindent\refhg}
\def\naive{\hbox{naive}}
\def\itemitem{\par\indent \hangindent2\parindent \textindent}
\def\var{\hbox{var}}
\def\Corr{\hbox{Corr}}
\def\Corr{\hbox{Corr}}
\def\trace{\hbox{trace}}
\def\refhg{\hangindent=20pt\hangafter=1}
\def\refmark{\par\vskip 2mm\noindent\refhg}
\def\Normal{\hbox{Normal}}
\def\povr{\buildrel p\over\to}
\def\ccdot{{\bullet}}
\def\bse{\begin{eqnarray*}}
\def\ese{\end{eqnarray*}}
\def\be{\begin{eqnarray}}
\def\ee{\end{eqnarray}}
\def\bq{\begin{equation}}
\def\eq{\end{equation}}
\def\bse{\begin{eqnarray*}}
\def\ese{\end{eqnarray*}}
\def\pr{\hbox{pr}}
\def\wh{\widehat}
\def\trans{^{\rm T}}
\def\myalpha{{\cal A}}
\def\th{^{th}}

\newcommand{\bbR}{\mathbb{R}}
\newcommand{\bbX}{\mathbb{X}}
\newcommand{\bI}{\mathbf{I}}
\newcommand{\bM}{\mathbf{M}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\bZ}{\mathbf{Z}}
\newcommand{\bA}{\mathbf{A}}
\newcommand{\bB}{\mathbf{B}}
\newcommand{\bC}{\mathbf{C}}
\newcommand{\bD}{\mathbf{D}}
\newcommand{\bF}{\mathbf{F}}
\newcommand{\bG}{\mathbf{G}}
\newcommand{\bP}{\mathbf{P}}
\newcommand{\bR}{\mathbf{R}}
\newcommand{\bS}{\mathbf{S}}
\newcommand{\bU}{\mathbf{U}}
\newcommand{\bV}{\mathbf{V}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bL}{\mathbf{L}}
\newcommand{\bW}{\mathbf{W}}
\newcommand{\bT}{\mathbf{T}}
\newcommand{\bH}{\mathbf{H}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\ba}{\mathbf{a}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bm}{\mathbf{m}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bd}{\mathbf{d}}
\newcommand{\bt}{\mathbf{t}}
%\newcommand{\be}{\mathbf{\mathcal{E}}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bdelta}{\boldsymbol{\delta}}
\newcommand{\bepsilon}{\boldsymbol{\epsilon}}
\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bnu}{\boldsymbol{\nu}}
%\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bLambda}{\boldsymbol{\psi}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bGamma}{\boldsymbol{\Gamma}}
\newcommand{\bOmega}{\boldsymbol{\Omega}}
\newcommand{\bDelta}{\boldsymbol{\Delta}}
\newcommand{\bgamma}{\boldsymbol{\gamma}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bxi}{\boldsymbol{\xi}}
\newcommand{\bomega}{\boldsymbol{\omega}}
\newcommand{\0}{\mathbf{0}}
\newcommand{\1}{\mathbf{1}}
\newcommand*{\QEDB}{\hfill\ensuremath{\square}}
\DeclareRobustCommand{\rchi}{{\mathpalette\irchi\relax}}
\newcommand{\irchi}[2]{\raisebox{\depth}{$#1\chi$}} % inner command, used by \rchi
%\newcommand{\rchi}{\mathscr X}
\newcommand{\argmin}{\operatornamewithlimits{arg\,min}}
\newcommand{\argmax}{\operatornamewithlimits{arg\,max}}
\renewcommand{\arraystretch}{1.5}
%###################################

\numberwithin{equation}{section}
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{lemma}[thm]{Lemma}
\newcommand{\bl}{\color{blue}}

\allowdisplaybreaks
% If you set papersize explicitly, activate the following three lines:
\special{papersize = 8.5in, 11in}
\setlength{\pdfpageheight}{11in}
\setlength{\pdfpagewidth}{8.5in}

\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}

% If you use BibTeX in apalike style, activate the following line:
\bibliographystyle{apalike}

\begin{document}

% If your paper is accepted and the title of your paper is very long,
% the style will print as headings an error message. Use the following
% command to supply a shorter title of your paper so that it can be
% used as headings.
%
%\runningtitle{I use this title instead because the last one was very long}

% If your paper is accepted and the number of authors is large, the
% style will print as headings an error message. Use the following
% command to supply a shorter version of the authors names so that
% they can be used as headings (for example, use only the surnames)
%
%\runningauthor{Surname 1, Surname 2, Surname 3, ...., Surname n}

% Supplementary material: To improve readability, you must use a single-column format for the supplementary material.
\onecolumn
\aistatstitle{On Some Fast And Robust Classifiers For High Dimension, Low Sample Size Data:
Supplementary Material}
\section*{MATHEMATICAL DETAILS AND PROOFS}
\begin{tcolorbox}[colback = white]
We will use the following definitions while presenting the mathematical details.
\begin{enumerate}
 \item $a_n=o(b_n)$ as $n\to\infty$ implies that for every $\epsilon>0$ there exists an $N\in\mathbb{N}$ such that $|a_n/b_n|<\epsilon$ for all $n\geq N$.
 \item $a_n=O(b_n)$ as $n\to\infty$ implies that there exist $M>0$ and $N\in\mathbb{N}$ such that $|a_n/b_n|<M$ for all $n\geq N$.
\end{enumerate}
\end{tcolorbox}
\vspace{0.5cm}
\emph{The results up to Theorem 3.3 on concentration of probabilities in HDLSS asymptotic regime are derived for a fixed $n$ and $p\to\infty$}.\newline

\noindent {\bf Proof of Lemma 2.1}

Suppose $\bU\sim\bF_i$ and $\bV\sim\bF_j$ for $i,j\in\{1,2\}$ and $\bU,\bV$ are independent. We have assumed in A0.2 that the limiting constants $\nu_{ij},\sigma^2_i$ for $i,j\in\{1,2\}$ exist. Fix $\epsilon>0$. Now, observe that
\begin{align*}
\ {\rm P}\bigg [\bigg |\frac{1}{p}\bU^\top\bV - \nu_{ij}\bigg |>\epsilon\bigg ]
=&\ {\rm P}\bigg [\bigg |\frac{1}{p}\bU^\top\bV - \frac{1}{p}\bmu_i^\top\bmu_j + \frac{1}{p}\bmu_i^\top\bmu_j - \nu_{ij}\bigg |>\epsilon\bigg ]\\
\leq &\ {\rm P}\bigg [\bigg |\frac{1}{p}\bU^\top\bV - \frac{1}{p}\bmu_i^\top\bmu_j\bigg |>\frac{\epsilon}{2}\bigg ] + {\rm I}\bigg [\bigg |\frac{1}{p}\bmu_i^\top\bmu_j - \nu_{ij}\bigg |>\frac{\epsilon}{2}\bigg ]\ [\text{follows from the union bound}].
\end{align*}
So, we get
\begin{align}\label{ref1}
&\ {\rm P}\bigg [\bigg |\frac{1}{p}\bU^\top\bV - \frac{1}{p}\bmu_i^\top\bmu_j\bigg |>\frac{\epsilon}{2}\bigg ]\\
= &\ {\rm P}\left [\bigg |\frac{1}{p}\sum_{k=1}^p U_{k}V_k - \frac{1}{p}\sum_{k=1}^p {\rm E}[ U_{k}]{\rm E}[V_k]\bigg |>\frac{\epsilon}{2}\right]\nonumber\\
\leq &\ \frac{4}{\epsilon^2}{\rm Var}\bigg [\frac{1}{p}\sum_{k=1}^p U_{k}V_{k}\bigg ]\ [\text{follows from Chebyshev's inequality}]\nonumber \\
=&\ \frac{4}{\epsilon^2 p^2}\sum_{k=1}^p {\rm Var}\big [U_{k}V_{k})\big ]
 +\frac{8}{\epsilon^2 p^2}\mathop{\sum\sum}_{1\leq k< k^\prime\leq p} {\rm Cov}\left(U_{k}V_{k},U_{k^\prime}V_{k^\prime}\right)\nonumber \\
\leq &\ \frac{4}{\epsilon^2 p^2}\sum_{k=1}^p {\rm E}\big [U^2_{k}V^2_{k})\big ]
 +\frac{8}{\epsilon^2 p^2}\mathop{\sum\sum}_{1\leq k< k^\prime\leq p} {\rm Corr}\left(U_{k}V_{k},U_{k^\prime}V_{k^\prime}\right)\sqrt{{\rm E}\big [U^2_{k}V^2_{k})\big ]\ {\rm E}\big [U^2_{k^\prime}V^2_{k^\prime})\big ]}\nonumber \\
 \leq &\ \frac{4C}{\epsilon^2 p}
 +\frac{8C}{\epsilon^2 p^2}\mathop{\sum\sum}_{1\leq k< k^\prime\leq p} {\rm Corr}\left(U_{k}V_{k},U_{k^\prime}V_{k^\prime}\right)\ [\text{for some }C<\infty\ (\text{due to A0.1})]\nonumber \\
 =&\ o(1)\text{ as }p\to\infty\ [\text{follows from A0.3}].
\end{align}
Also, since $\lim_{p\to\infty}\bmu_i^\top\bmu_j=\nu_{ij}$, there exists $p_0\in\mathbb{N}$ such that ${\rm I}\left [\left |\frac{1}{p}\bmu_i^\top\bmu_j - \nu_{ij}\right |>\frac{\epsilon}{2}\right ]=0$ for all $p\geq p_0$. Therefore, ${\rm P}\left [\left |\frac{1}{p}\bU^\top\bV - \nu_{ij}\right |>\epsilon\right ]\leq {\rm P}\left [\left |\frac{1}{p}\bU^\top\bV - \frac{1}{p}\bmu_i^\top\bmu_j\right |>\frac{\epsilon}{2}\right ] =o(1)$ for $\bU\sim\bF_i$ and $\bV\sim\bF_j$, $i,j\in\{1,2\}$ as $p\to\infty$.

Following similar arguments, one can also prove that (as $p\to\infty$),
\begin{align*}
&\ {\rm P}\left [\left |\frac{1}{p}\|\bU\|^2 - \frac{1}{p}{\rm E}[\|\bU\|^2]\right |>\epsilon\right ]\leq o(1)\\
\text{i.e.,} &\ {\rm P}\left [\left |\frac{1}{p}\|\bU\|^2 - \frac{1}{p}\left \{\|\bmu_i\|^2 + tr (\Sigma_i)\right \}\right |>\epsilon\right ]\leq o(1)\\
\text{i.e.,} &\ {\rm P}\left [\left |\frac{1}{p}\|\bU\|^2 - \left \{\nu_{ii} + \sigma_i\right \}\right |>\epsilon\right ]\leq o(1)\ [\text{since }\lim_{p\to\infty}\|\bmu_i\|^2/p=\nu_{ii}\text{ and }\lim_{p\to\infty}tr (\Sigma_i)=\sigma^2_i].
\end{align*}
Using the continuous mapping theorem (repeatatively), we obtain
$$\sin (2\pi h(\bU,\bV))=\frac{1+\bU^\top\bV}{\sqrt{(1+\|\bU\|^2)(1+\|\bV\|^2)}}=\frac{\frac{1}{p}+\frac{\bU^\top\bV}{p}}{\sqrt{\left (\frac{1}{p}+\frac{\|\bU\|^2}{p}\right )\left(\frac{1}{p}+\frac{\|\bV\|^2}{p}\right)}}\stackrel{\rm P}{\to}\frac{\nu_{ij}}{\sqrt{(\sigma^2_i+\nu_{ii})(\sigma^2_j+\nu_{jj})}}$$ as $p\to\infty$. Hence, the proof. \hfill\QEDB\newline

Note that $h(\bU,\bV)\stackrel{\rm P}{\to}\frac{1}{2\pi}\sin^{-1}\left \{\frac{\nu_{ij}}{\sqrt{(\sigma^2_i+\nu_{ii})(\sigma^2_j+\nu_{jj})}}\right\}$ as $p\to\infty$. We define $\tau_{ii}=\frac{1}{2\pi}\sin^{-1}\left \{\frac{\nu_{ii}}{(\sigma^2_i + \nu_{ii})}\right\}$ for $i=1,2$, and $\tau_{12}=\frac{1}{2\pi}\sin^{-1}\left \{\frac{\nu_{12}}{\sqrt{(\sigma^2_1 + \nu_{11})(\sigma^2_2 + \nu_{22})}}\right\}$. Therefore, $h(\bU,\bV)\stackrel{\rm P}{\to}\tau_{ij}$ as $p\to\infty$, where $\bU\sim\bF_i$, $\bV\sim\bF_j$, and $\bU,\bV$ are indepedently distributed.
\begin{cor}\label{L0}
 For $i,j\in\{1,2\}$, if {\rm A0.1-A0.3} is satisfied, then
 \begin{enumerate}[(a)]
  \item $|T_{ij}-\tau_{ij}|\stackrel{\rm P}{\to}0$ as $p\to\infty $, and
  \item if $\bZ\sim \bF_j$, then $|T_{i}(\bZ)-\tau_{ij}|\stackrel{\rm P}{\to}0$ as $p\to\infty $.
 \end{enumerate}
\end{cor}
\noindent {\bf Proof of Corollary \ref{L0}}
\begin{enumerate}[(a)]
 \item Fix $\epsilon>0$. It follows from Lemma 2.1 that
\begin{align}\label{ref1}
&\ {\rm P}\big [\big |T_{11} - \tau_{11}\big |>\epsilon\big ]\nonumber\\
= &\ {\rm P} \bigg [\bigg |\frac{1}{n_1(n_1-1)}\sum\limits_{1\leq i\neq j\leq n_1}\left\{{h}(\bX_{i},\bX_{j})-\tau_{11}\right\}\bigg |>\epsilon \bigg]\nonumber\\
\leq &\ {\rm P} \bigg [\frac{1}{n_1(n_1-1)}\sum\limits_{1\leq i\neq j\leq n_1}\left |{h}(\bX_{i},\bX_{j}) -\tau_{11}\right |>\epsilon \bigg]\nonumber \\
\leq &\ \sum\limits_{1\leq i\neq j\leq n_1}{\rm P} \left [\left |{h}(\bX_{i},\bX_{j}) -\tau_{11}\right |>\epsilon \right]\nonumber\\
=&\ n_1(n_1-1)o(1)=\ o(1)\text{ as }p\to\infty\ [\text{since $n_1$ is fixed}].
\end{align}
Therefore, $|T_{11}-\tau_{11}|\stackrel{\rm P}{\to}0$ as $p\to\infty$. Similarly, $|T_{12}-\tau_{12}|$ and $|T_{22}-\tau_{22}|$ also converge to 0 in probability as $p\to\infty$.
\item Fix $\epsilon>0$. Let $\bU\in\rchi_i$ and $\bZ\sim\bF_j$ for $i,j\in\{1,2\}$. Since $n_i$ is fixed for $i\in\{1,2\}$, from Lemma 2.1, we have
\begin{align}\label{ref3}
{\rm P}\big [\big |T_{i}(\bZ) - \tau_{ij}\big |>\epsilon\mid\bZ\sim\bF_j\big ]
=&\  {\rm P}\left [\left |\left \{\frac{1}{n_i}\sum_{\bU\in\rchi_i}\big \{h(\bU,\bZ) - {\rm E}[h(\bU,\bZ)\mid\bZ\sim\bF_j]\big \}\right \}\right |>\epsilon\mid\bZ\sim\bF_j \right ]\nonumber\\
\leq &\ {\rm P}\left [\frac{1}{n_i}\sum_{\bU\in\rchi_i}\left |h(\bU,\bZ) - {\rm E}[h(\bU,\bZ)\mid\bZ\sim\bF_j]\right |>\epsilon \mid\bZ\sim\bF_j\right ]\nonumber \\
\leq &\ \sum_{\bU\in\rchi_i}{\rm P}\left [\left |h(\bU,\bZ) - {\rm E}[h(\bU,\bZ)\mid\bZ\sim\bF_j]\right |>\epsilon \mid\bZ\sim\bF_j\right ]\nonumber \\
\leq &\ n_io(1)=o(1)\text{ as }p\to\infty.
\end{align}
\end{enumerate}
Hence, the proof. \hfill \QEDB\newline

Recall the definition of $\tau_0$ given as
\begin{align*}
 &\ \tau_0 = \frac{1}{2\pi}\sin^{-1}\left \{\frac{\nu_{11}}{(\sigma^2_1 + \nu_{11})}\right\}+ \frac{1}{2\pi}\sin^{-1}\left \{\frac{\nu_{22}}{(\sigma^2_2 + \nu_{22})}\right\}- \frac{1}{\pi}\sin^{-1}\left \{\frac{\nu_{12}}{\sqrt{(\sigma^2_1 + \nu_{11})(\sigma^2_2 + \nu_{22})}}\right\}\\
 \text{i.e., }&\ \tau_0=\tau_{11}+\tau_{22}-2\tau_{12}.
\end{align*}
Note that if $\nu_{11}=\nu_{12}=\nu_{22}=0$, then $\tau_0=0$. Also, if $\nu_{11}=\nu_{12}=\nu_{22}$ and $\sigma^2_1=\sigma^2_2$, then $\tau_0=0$.
\begin{cor}\label{C0}
 Suppose {\rm A0.1-A0.3} are satisfied. Let $\bZ\in\mathbb{R}^p$ be a test observation.
%  \vspace{-0.1cm}
%\begin{small}
\begin{enumerate}[(a)]
\item  $\begin{aligned}[t]&\text{If }\bZ\sim\bF_1,\text{ then }
|L_2(\bZ)- L_1(\bZ) - \tau_0|\stackrel{\rm P}{\to}0\text{ as } p\to\infty .
 \end{aligned}$
%\end{small}
%\vspace{-0.15cm}
\item  $\begin{aligned}[t]&\text{If }\bZ\sim\bF_2,\text{ then }
 |L_2(\bZ)- L_1(\bZ) + \tau_0|\stackrel{\rm P}{\to}0\text{ as } p\to\infty.
 \end{aligned}$
\end{enumerate}
\end{cor}
\noindent {\bf Proof of Corollary \ref{C0}}
\begin{enumerate}[(a)]
 \item Note that $$L_2(\bZ)- L_1(\bZ)= \{T_{22}-2T_2(\bZ)\}- \{T_{11} - 2T_1(\bZ)\}.$$ If $\bZ\sim\bF_1$, then it follows from Corollary \ref{L0} that $L_2(\bZ)-L_1(\bZ)$ converges in probabiliy to $\{\tau_{22} - 2 \tau_{12}\} -\{ \tau_{11}-2\tau_{11}\}=\tau_{11}  + \tau_{22}- 2 \tau_{12}=\tau_0$ as $p\to\infty$.
 \item Similarly, if $\bZ\sim\bF_2$, $L_2(\bZ)-L_1(\bZ)$ converges in probabiliy to $\{\tau_{22} - 2 \tau_{22}\} -\{ \tau_{11}-2\tau_{12}\}=-\{\tau_{11}  + \tau_{22}- 2 \tau_{12}\}=-\tau_0$ as $p\to\infty$.
\end{enumerate}
Hence, the proof. \hfill\QEDB\newline

\noindent {\bf Proof of Theorem 2.2}

The prior probability of an observation $\bZ$ belonging to the first class is given by $\pi_1$ ($0<\pi_1<1$). The misclassification probability of $\delta_0$ is as follows:
\begin{align}\label{ref501}
{\rm P}[\delta_0(\bZ)\neq \text{ true label of }\bZ]
 =&\ \pi_1 {\rm P}[\delta_0(\bZ)=2\mid \bZ\sim\bF_1] + (1-\pi_1){\rm P}[\delta_0(\bZ)=1\mid \bZ\sim\bF_2]\nonumber \\
 =&\ \pi_1 {\rm P}[L_2(\bZ)\leq L_1(\bZ)\mid \bZ\sim\bF_1]+ (1-\pi_1){\rm P}[L_2(\bZ)> L_1(\bZ)\mid \bZ\sim\bF_2].
\end{align}
We have assumed that either $(a)\ \nu_{11},\nu_{12},\nu_{22}$ are unequal, or $(b)\ \nu_{11}=\nu_{12}=\nu_{22}\neq \0$, and $\sigma_1^2=\sigma_2^2$. As a result, $\tau_0$ is strictly positive. Fix $0<\epsilon<\tau_0$. Now, we have
\begin{align}\label{ref502}
{\rm P}\big [L_2(\bZ)\leq L_1(\bZ)\mid \bZ\sim\bF_1\big ]
&\ \leq {\rm P}\big [L_2(\bZ)- L_1(\bZ)\leq \tau_0-\epsilon\mid \bZ\sim\bF_1\big ]\nonumber \\
&\ \leq {\rm P}\big [L_2(\bZ)- L_1(\bZ)- \tau_0 \leq -\epsilon\mid \bZ\sim\bF_1\big ]\nonumber \\
&\ \leq {\rm P}\big [|L_2(\bZ)- L_1(\bZ) - \tau_0|>\epsilon\mid \bZ\sim\bF_1\big ]\nonumber\\
&\ =o(1)\text{ as }p\to\infty\ [\text{follows from Corollary \ref{C0}}].
\end{align}
Similarly,
\begin{align}\label{ref503}
{\rm P}\big [L_2(\bZ)> L_1(\bZ)\mid \bZ\sim\bF_2\big ]
\leq &\ {\rm P}\big [L_2(\bZ)- L_1(\bZ)> -\tau_0+\epsilon\mid \bZ\sim\bF_2\big ]\nonumber \\
\leq &\ {\rm P}\big [L_2(\bZ)- L_1(\bZ)+ \tau_0 > \epsilon\mid \bZ\sim\bF_2\big ]\nonumber \\
\leq &\ {\rm P}\big [|L_2(\bZ)- L_1(\bZ) + \tau_0|>\epsilon\mid \bZ\sim\bF_2\big ]\nonumber\\
=&\ o(1)\text{ as }p\to\infty\ [\text{follows from Corollary \ref{C0}}].
\end{align}
Combining Eqs. \eqref{ref501}, \eqref{ref502} and \eqref{ref503}, we get ${\rm P}[\delta_0(\bZ)\neq \text{ true label of }\bZ]=o(1)$ as $p\to\infty$.\hfill\QEDB\newline

\begin{lemma}\label{L2}
  For $j,j^\prime\in\{1,2\}$, if {\rm A1} is satisfied, then 
 \begin{enumerate}[(a)]
  \item $|\bar{T}_{jj^\prime}-\bar{\tau}_p(j,j^\prime)|\stackrel{\rm P}{\to}0$ as $p\to\infty $, and 
  \item if $\bZ\sim \bF_j$, then $|\bar{T}_{j^\prime}(\bZ)-\bar{\tau}_p(j,j^\prime)|\stackrel{\rm P}{\to}0$ as $p\to\infty $.
 \end{enumerate}
\end{lemma}
\noindent {\bf Proof of Lemma \ref{L2}}
\begin{enumerate}[(a)]
 \item Fix $\epsilon>0$. We have
\begin{align}\label{ref1}
&\ {\rm P}\big [\big |\bar{T}_{11} - \bar{\tau}_p(1,1)\big |>\epsilon\big ]\nonumber\\
= &\ {\rm P} \bigg [\bigg |\frac{1}{n_1(n_1-1)}\sum\limits_{1\leq i\neq j\leq n_1}\bar{h}(\bX_{i},\bX_{j})-{\rm E}[\bar{h}(\bX_{1},\bX_{2})]\bigg |>\epsilon \bigg]\ [\text{follows from the definitions of }\bar{T}_{11}\text{ and }\bar{\tau}_p(1,1)]\nonumber\\
= &\ {\rm P} \bigg [\bigg |\frac{1}{p}\sum_{k=1}^p \frac{1}{n_1(n_1-1)}\sum\limits_{1\leq i\neq j\leq n_1}{h}(X_{ik},X_{jk})-\frac{1}{p}\sum_{k=1}^p {\rm E}\ h(X_{1k},X_{2k})\bigg |>\epsilon \bigg]\ [\text{follows from the definition of }\bar{h}_p(\cdot,\cdot)]\nonumber\\
= &\ {\rm P} \bigg [\bigg |\frac{1}{n_1(n_1-1)}\sum\limits_{1\leq i\neq j\leq n_1}\bigg \{\frac{1}{p}\sum_{k=1}^p {h}(X_{ik},X_{jk}) -\frac{1}{p}\sum_{k=1}^p {\rm E}\ h(X_{1k},X_{2k})\bigg \}\bigg |>\epsilon \bigg]\nonumber \\
\leq &\ {\rm P} \bigg [\frac{1}{n_1(n_1-1)}\sum\limits_{1\leq i\neq j\leq n_1}\bigg |\frac{1}{p}\sum_{k=1}^p {h}(X_{ik},X_{jk}) -\frac{1}{p}\sum_{k=1}^p {\rm E}\ h(X_{1k},X_{2k})\bigg |>\epsilon \bigg]\ [\text{follows from the triangle ineq.}]\nonumber \\
\leq &\ \sum\limits_{1\leq i\neq j\leq n_1}{\rm P} \bigg [\bigg |\frac{1}{p}\sum_{k=1}^p \big \{{h}(X_{ik},X_{jk}) -{\rm E}\ h(X_{1k},X_{2k})\big \}\bigg |>\epsilon \bigg]\ [\text{using the union bound}]\nonumber \\
\leq &\ \sum\limits_{1\leq i\neq j\leq n_1} \frac{1}{\epsilon^2}{\rm Var}\bigg [\frac{1}{p}\sum_{k=1}^p h(X_{ik},X_{jk})\bigg ]\ [\text{follows from Chebyshev's inequality}].
\end{align}
We will show that the vaiance of $\frac{1}{p}\sum_{k=1}^p h(X_{ik},X_{jk})$ (for all $i\neq j$) converges in probability to 0 as $p\to\infty.$

Fix $1\leq i,j\leq n_1$ (with $i\neq j$). Observe that
\begin{align}\label{ref2}
{\rm Var}\bigg [\frac{1}{p}\sum_{k=1}^p h(X_{ik},X_{jk})\bigg ]
=\ \frac{1}{p^2}\sum_{k=1}^p {\rm Var}\big [h(X_{ik},X_{jk})\big ]
 +\frac{2}{p^2}\mathop{\sum\sum}_{1\leq k< k^\prime\leq p} {\rm Cov}\left(h(X_{ik},X_{jk}),h(X_{ik^\prime},X_{jk^\prime})\right).
\end{align}
Since, $0\leq h\leq 1,{\rm Var}\big [h(X_{ik},X_{jk})\big ]\leq 1$ for all $k=1,\ldots,p.$ Using the inequality ${\rm Cov}(X,Y)\leq {\rm Corr}(X,Y)\sqrt{{\rm E}(X^2){\rm E}(Y^2)}$ and the boundedness of $h$, we get
\begin{align*}
{\rm Cov}\left(h(X_{ik},X_{jk}),h(X_{ik^\prime},X_{jk^\prime})\right)\leq {\rm Corr}\left(h(X_{ik},X_{jk}),h(X_{ik^\prime},X_{jk^\prime})\right)\text{ for all }1\leq k<k^\prime\leq p.
\end{align*}
Since A1 is satisfied, from \eqref{ref2} we obtain
\begin{align*}
{\rm Var}\bigg [\frac{1}{p}\sum_{k=1}^p h(X_{ik},X_{jk})\bigg ]
\leq \frac{1}{p} +\frac{2}{p^2}\mathop{\sum\sum}_{1\leq k< k^\prime\leq p} {\rm Corr}\left(h(X_{ik},X_{jk}),h(X_{ik^\prime},X_{jk^\prime})\right)
= o(1)\text{ as }p\to\infty.
\end{align*}
Since $n_1$ is finite, it now follows from \eqref{ref1} that $|\bar{T}_{11}-\bar{\tau}_p(1,1)|\stackrel{\rm P}{\to}0$ as $p\to\infty.$ Following similar arguments one can show that if A1 is satisfied, then $|\bar{T}_{12}-\bar{\tau}_p(1,2)|$ and $|\bar{T}_{22}-\bar{\tau}_p(2,2)|$ also converge to 0 in probability as $p\to\infty$.

\item Fix $\epsilon>0,$ and recall the definitions of $\bar{T}_{1}(\bZ)$ and $\bar{\tau}_p(1,1)$. We have
\begin{align}\label{ref3}
&\ {\rm P}\big [\big |\bar{T}_{1}(\bZ) - \bar{\tau}_p(1,1)\big |>\epsilon\mid \bZ\sim\bF_1\big ]\nonumber \\
= &\ {\rm P}\left [\bigg |\frac{1}{p}\sum_{k=1}^p T_{1k}(Z_k) - \frac{1}{p}\sum_{k=1}^p {\rm E}\ h(X_{1k},X_{2k})\bigg |>\epsilon\mid \bZ\sim\bF_1 \right ]\nonumber \\
= &\ {\rm P}\bigg [\bigg |\frac{1}{p}\sum_{k=1}^p \bigg \{\frac{1}{n_1}\sum_{i=1}^{n_1}\big \{h(X_{ik},Z_k) - {\rm E}[h(X_{1k},Z_k)\mid \bZ\sim\bF_1]\big \}\bigg \}\bigg |>\epsilon\mid \bZ\sim\bF_1 \bigg ]\nonumber \\
= &\ {\rm P}\bigg [\bigg |\frac{1}{n_1}\sum_{i=1}^{n_1}\bigg \{\frac{1}{p}\sum_{k=1}^p\big \{h(X_{ik},Z_k) - {\rm E}[h(X_{1k},Z_k)\mid \bZ\sim\bF_1]\big \}\bigg \}\bigg |>\epsilon\mid \bZ\sim\bF_1 \bigg ]\nonumber \\
\leq &\ {\rm P}\bigg [\frac{1}{n_1}\sum_{i=1}^{n_1}\bigg |\frac{1}{p}\sum_{k=1}^p\big \{h(X_{ik},Z_k) - {\rm E}[h(X_{1k},Z_k)\mid \bZ\sim\bF_1]\big \}\bigg |>\epsilon\mid \bZ\sim\bF_1 \bigg ]\ [\text{follows from the triangle ineq.}]\nonumber \\
\leq &\ \sum_{i=1}^{n_1}{\rm P}\bigg [\bigg |\frac{1}{p}\sum_{k=1}^p\big \{h(X_{ik},Z_k) - {\rm E}[h(X_{1k},Z_k)\mid \bZ\sim\bF_1]\big \}\bigg |>\epsilon\mid \bZ\sim\bF_1 \bigg ]\ [\text{using the union bound}]\nonumber \\
\leq &\ \sum_{i=1}^{n_1}\frac{1}{\epsilon^2}{\rm Var}\bigg [\frac{1}{p}\sum_{k=1}^p h(X_{ik},Z_k)\mid \bZ\sim \bF_1\bigg ]=  \sum_{i=1}^{n_1}\frac{1}{\epsilon^2}{\rm Var}\bigg [\frac{1}{p}\sum_{k=1}^p h(X_{ik},X^\prime_k)\bigg ],
\end{align}
where $\bX^\prime=(X^\prime_1,\ldots, X^\prime_p)^\top\sim\bF_1$ and independent from $\rchi_1.$ We have already shown in the proof of Lemma \ref{L2}(a) that ${\rm Var}\big [\frac{1}{p}\sum_{k=1}^p h(X_{ik},X^\prime_k)\big ]=o(1)$ as $p\to\infty$ due to boundedness of $h$ and assumption A1. Since $n_1$ is fixed, $\sum_{i=1}^{n_1}{\rm Var}\big [\frac{1}{p}\sum_{k=1}^p h(X_{ik},X^\prime_k)\big ]=o(1)$ as $p\to\infty$. Therefore, it follows from \eqref{ref3} that $\big |\bar{T}_{1}(\bZ) - \bar{\tau}_p(1,1)\big |$ converges in probability to 0 as $p\to\infty$ (when $\bZ\sim\bF_1$).

Following similar arguments, one can prove that for every $\epsilon >0,$
\begin{align*}
\lim_{p\to\infty}{\rm P}\big[\big |\bar{T}_{2}(\bZ) - \bar{\tau}_p(1,2)\big |>\epsilon\mid\bZ\sim\bF_1\big ]=&\lim_{p\to\infty}{\rm P}\big[\big |\bar{T}_{1}(\bZ) - \bar{\tau}_p(1,2)\big |>\epsilon\mid\bZ\sim\bF_2\big ]\\
=&\lim_{p\to\infty}{\rm P}\big[\big |\bar{T}_{2}(\bZ) - \bar{\tau}_p(2,2)\big |>\epsilon\mid\bZ\sim\bF_2\big ]=0.
\end{align*}
\end{enumerate}\hfill \QEDB\newline

\noindent {\bf Proof of Lemma 3.1}

Recall that $\bar{L}_1(\bZ) = \bar{T}_{11} - 2\bar{T}_{1}(\bZ),\ \tilde{L}_{2}(\bZ) = \bar{T}_{22} - 2\bar{T}_{2}(\bZ)$, and
\begin{align}\label{ref6}
 \theta(\bZ) =&\ \frac{1}{2}\bar{T}(\bar{L}_2(\bZ)-\bar{L}_1(\bZ)) + \frac{1}{2}(\bar{T}_{22}-\bar{T}_{11})(\bar{L}_2(\bZ)+\bar{L}_1(\bZ)+2\bar{T}_{12})\nonumber \\
 =&\ \frac{1}{2}\big \{(\bar{T}_{11}-2\bar{T}_{12}+\bar{T}_{22})\times (\bar{L}_2(\bZ)-\bar{L}_1(\bZ))\big \}\nonumber \\
 &\ +\frac{1}{2}\big \{(\bar{T}_{22}-\bar{T}_{11})\times (\bar{T}_{22} - 2\bar{T}_2(\bZ) + \bar{T}_{11} - 2\bar{T}_1(\bZ)+2\bar{T}_{12})\big \}.
\end{align}
Let us denote $\bar{L}_2(\bZ)-\bar{L}_1(\bZ)$ by $\bar{L}(\bZ)$ and $\bar{T}_{22} - 2\bar{T}_2(\bZ) + \bar{T}_{11} - 2\bar{T}_1(\bZ)+2\bar{T}_{12}$ by $\bar{S}(\bZ)$.
\begin{align}\label{ref7}
\hspace{-1.4in}\text{Therefore, we can write }\theta(\bZ) = \frac{1}{2}\big \{(\bar{T}_{11}-2\bar{T}_{12}+\bar{T}_{22})\times \bar{L}(\bZ)\big \}
 +\frac{1}{2}\big \{(\bar{T}_{22}-\bar{T}_{11})\times \bar{S}(\bZ)\big \}.
\end{align}
\begin{enumerate}[(a)]
 \item Fix $\epsilon >0.$ Now,
\begin{align}\label{ref4}
 &\ {\rm P}\big [|\bar{L}_2(\bZ)- \bar{L}_1(\bZ) - \bar{\tau}_p|>\epsilon\mid \bZ\sim\bF_1\big ]\nonumber \\
 =&\ {\rm P}\big [|\{\bar{T}_{22} - 2\bar{T}_2(\bZ)- \bar{T}_{11} + 2\bar{T}_1(\bZ)\}
 - \{\bar{\tau}_p(1,1) - 2\bar{\tau}_p(1,2) +\bar{\tau}_p(2,2)\}|>\epsilon\mid \bZ\sim\bF_1\big ]\nonumber \\
 \leq &\ {\rm P}\big [|\{\bar{T}_{22} - 2\bar{T}_2(\bZ)- \bar{T}_{11} + 2\bar{T}_1(\bZ)\}- \{2\bar{\tau}_p(1,1) -\bar{\tau}_p(1,1) - 2\bar{\tau}_p(1,2) +\bar{\tau}_p(2,2)\}|>\epsilon\mid \bZ\sim\bF_1\big ]\nonumber \\
 \leq &\ {\rm P}\left [|\bar{T}_{11}-\bar{\tau}_p(1,1)|>\frac{\epsilon}{4}\right ] + {\rm P}\left [|\{\bar{T}_{22} - \bar{\tau}_p(2,2)|>\frac{\epsilon}{4}\right ]\nonumber \\
 &\ \ + {\rm P}\left [2|\bar{T}_2(\bZ)- \bar{\tau}_p(1,2)|>\frac{\epsilon}{4}\mid \bZ\sim\bF_1\right ]+ {\rm P}\left [2|\bar{T}_1(\bZ) - \bar{\tau}_p(1,1)|>\frac{\epsilon}{4}\mid \bZ\sim\bF_1\right ]\nonumber \\
 =&\ o(1)\text{ as }p\to\infty\ [\text{following Lemma \ref{L2}}].
\end{align}
Therefore, if $\bZ\sim\bF_1$, then $|\bar{L}_2(\bZ)- \bar{L}_1(\bZ) - \bar{\tau}_p|\stackrel{\rm P}{\to}0$ as $p\to\infty$. This proves the first part of Lemma 3.1(a).
Next, we use the continuous mapping theorem and Lemma \ref{L2} to obtain the following:
\begin{align*}
 &\ |(\bar{T}_{11}-2\bar{T}_{12}+\bar{T}_{22})- \bar{\tau}_p|\stackrel{\rm P}{\to}0,\\
 &\ |(\bar{T}_{22}-\bar{T}_{11})- (\bar{\tau}_p(2,2)-\bar{\tau}_p(1,1))|\stackrel{\rm P}{\to}0\text{ and }\\
 &\ |\bar{S}(\bZ)-(\bar{\tau}_p(2,2)-\bar{\tau}_p(1,1))|\stackrel{\rm P}{\to}0\ (\text{if }\bZ\sim\bF_1)\text{ as }p\to\infty.
%  &|S_1(\bZ)+\bar{\tau}_p|\stackrel{\rm P}{\to}0,\text{ and }
%  \ |S_2(\bZ)+(\bar{\tau}_p(2,2)- \bar{\tau}_p(1,1))\stackrel{\rm P}{\to}0,\text{ if }\bZ\sim\bF_2,
\end{align*}
Using the continuous mapping theorem once again, we conclude from \eqref{ref7} that if $\bZ\sim\bF_1$, then
\begin{align}\label{ref8}
 &\ \left |\theta(\bZ) - \left \{\frac{1}{2}\bar{\tau}_p^2 + \frac{1}{2}(\bar{\tau}_p(2,2)-\bar{\tau}_p(1,1))^2\right \}\right |\stackrel{\rm P}{\to}0\text{ as }p\to\infty\nonumber \\
 \text{i.e., }&\ |\theta(\bZ) - \bar{\psi}_p|\stackrel{\rm P}{\to}0\ (\text{if }\bZ\sim\bF_1)\text{ as }p\to\infty.
%  &\ |\theta(\bZ) + \{\frac{1}{2}\bar{\tau}^2 + \frac{1}{2}(\bar{\tau}_p(2,2)-\bar{\tau}_p(1,1))^2\}|\stackrel{\rm P}{\to}0,\text{ if }\bZ\sim\bF_2,
\end{align}

\item The arguments for this part of the proof are similar to part (a), and we skip it.\hfill\QEDB\newline
% Following similar arguments, one can show that for every $\epsilon >0$, ${\rm P}\big [|\bar{L}_2(\bZ)- \bar{L}_1(\bZ) + \bar{\tau}|>\epsilon\mid \bZ\sim\bF_2\big ]=o(1).$
\end{enumerate}

\noindent {\bf Proof of Theorem 3.2}
Recall that the prior probability of an observation $\bZ$ belonging to the first class is given by $\pi_1\ (0<\pi_1<1)$. The misclassification probability of the classifier $\delta_1$ can be written as
\begin{align}\label{ref5}
 {\rm P}[\delta_1(\bZ)\neq \text{ true label of }\bZ]
 =&\ \pi_1 {\rm P}[\delta_1(\bZ)=2\mid \bZ\sim\bF_1] + (1-\pi_1){\rm P}[\delta_1(\bZ)=1\mid \bZ\sim\bF_2]\nonumber \\
 =&\ \pi_1 {\rm P}[\bar{L}_2(\bZ)\leq \bar{L}_1(\bZ)\mid \bZ\sim\bF_1]+ (1-\pi_1){\rm P}[\bar{L}_2(\bZ)> \bar{L}_1(\bZ)\mid \bZ\sim\bF_2].
\end{align}
Since A2 is satisfied (i.e., $\liminf\limits_{p}\bar{\tau}_p>0$), we can choose $\epsilon>0 $ such that $\epsilon <\bar{\tau}_p$ for all $p\geq p_0$ for some $p_0\in\mathbb{N}.$ Therefore,
\begin{align*}
{\rm P}\big [\bar{L}_2(\bZ)\leq \bar{L}_1(\bZ)\mid \bZ\sim\bF_1\big ]
&\ \leq {\rm P}\big [\bar{L}_2(\bZ)- \bar{L}_1(\bZ)\leq \bar{\tau}_p-\epsilon\mid \bZ\sim\bF_1\big ]\\
&\ \leq {\rm P}\big [\bar{L}_2(\bZ)- \bar{L}_1(\bZ)- \bar{\tau}_p \leq -\epsilon\mid \bZ\sim\bF_1\big ]
\leq {\rm P}\big [|\bar{L}_2(\bZ)- \bar{L}_1(\bZ) - \bar{\tau}_p|>\epsilon\mid \bZ\sim\bF_1\big ]
\end{align*}
for all $p\geq p_0$. Then, it follows from Lemma 3.1(a) that ${\rm P}\big [\bar{L}_2(\bZ)\leq \bar{L}_1(\bZ)\mid \bZ\sim\bF_1\big ]=o(1)$ as $p\to\infty$.
Similarly,
\begin{align*}
{\rm P}\big [\bar{L}_2(\bZ)> \bar{L}_1(\bZ)\mid \bZ\sim\bF_2\big ]
\leq &\ {\rm P}\big [\bar{L}_2(\bZ)- \bar{L}_1(\bZ)> -\bar{\tau}_p+\epsilon\mid \bZ\sim\bF_2\big ]\\
\leq &\ {\rm P}\big [\bar{L}_2(\bZ)- \bar{L}_1(\bZ)+ \bar{\tau}_p > \epsilon\mid \bZ\sim\bF_2\big ]
\leq {\rm P}\big [|\bar{L}_2(\bZ)- \bar{L}_1(\bZ) + \bar{\tau}_p|>\epsilon\mid \bZ\sim\bF_2\big ]
\end{align*}
for all $p\geq p_0$. Since ${\rm P}\big [|\bar{L}_2(\bZ)- \bar{L}_1(\bZ) + \bar{\tau}_p|>\epsilon\mid \bZ\sim\bF_2\big ]=o(1)$ as $p\to\infty$ (due to Lemma 3.1(b)), ${\rm P}\big [\bar{L}_2(\bZ)> \bar{L}_1(\bZ)\mid \bZ\sim\bF_2\big ]=o(1)$ as $p\to\infty$. Consequently, it follows from Eq. \eqref{ref5} that ${\rm P}[\delta_1(\bZ)\neq \text{ true label of }\bZ]=\pi_1 o(1) + (1-\pi_1)o(1)=o(1)$ as $p\to\infty$. Hence, the proof.\hfill\QEDB\newline

\noindent {\bf Proof of Theorem 3.3}

First observe that
\begin{align*}
\ \liminf\limits_{p}\bar{\tau}_p>0
\Rightarrow  \liminf\limits_{p}\frac{1}{2}\bar{\tau}_p^2>0
\Rightarrow &\ \liminf\limits_{p}\frac{1}{2}\left \{\bar{\tau}_p^2 + (\bar{\tau}_p(2,2) - \bar{\tau}_p(1,1))^2\right \}>0.
\end{align*}
Thus, if A2 is satisfied, then $\liminf_p\bar{\psi}_p>0.$ Now, let us consider the misclassfication probability of $\delta_2.$
\begin{align}\label{ref9}
 {\rm P}[\delta_2(\bZ)\neq \text{ true label of }\bZ]
 =&\ \pi_1 {\rm P}[\delta_2(\bZ)=2\mid \bZ\sim\bF_1]+ (1-\pi_1){\rm P}[\delta_2(\bZ)=1\mid \bZ\sim\bF_2]\nonumber \\
 =&\ \pi_1 {\rm P}[\theta(\bZ)\leq 0\mid \bZ\sim\bF_1]+ (1-\pi_1){\rm P}[\theta(\bZ)> 0\mid \bZ\sim\bF_2].
\end{align}
Since $\liminf_p\bar{\psi}_p>0$, we can choose $\epsilon>0 $ such that $\epsilon <\bar{\psi}_p$ for all $p\geq p_1$ for some $p_1\in\mathbb{N}.$ Therefore,
\begin{align*}
{\rm P}\big [\theta(\bZ)\leq 0\mid \bZ\sim\bF_1\big ]\leq &\ {\rm P}\big [\theta(\bZ)\leq \bar{\psi}_p-\epsilon\mid \bZ\sim\bF_1\big ]\\
\leq &\ {\rm P}\big [\theta(\bZ)- \bar{\psi}_p \leq -\epsilon\mid \bZ\sim\bF_1\big ]
\leq {\rm P}\big [|\theta(\bZ) - \bar{\psi}_p|>\epsilon\mid \bZ\sim\bF_1\big ]\text{ for all }p\leq p_1.
\end{align*}
Therefore, it follows from Lemma 3.1(a) that ${\rm P}\big [\theta(\bZ)\leq 0\mid \bZ\sim\bF_1\big ]=o(1)$ as $p\to\infty$.
Similarly,
\begin{align*}
{\rm P}\big [\theta(\bZ)> 0\mid \bZ\sim\bF_2\big ]
\leq &\ {\rm P}\big [\theta(\bZ)> -\bar{\psi}_p+\epsilon\mid \bZ\sim\bF_1\big ]\\
\leq &\ {\rm P}\big [\theta(\bZ)+ \bar{\psi}_p > \epsilon\mid \bZ\sim\bF_2\big ]
\leq {\rm P}\big [|\theta(\bZ) + \bar{\psi}_p|>\epsilon\mid \bZ\sim\bF_2\big ]\text{ for all }p\geq p_1,
\end{align*}
implying ${\rm P}\big [\theta(\bZ)> 0\mid \bZ\sim\bF_2\big ]=o(1)$ as $p\to\infty$ (due to Lemma 3.1(b)). As a result, Using Eq. \eqref{ref9} we get ${\rm P}[\delta_2(\bZ)\neq \text{ true label of }\bZ]=\pi_1o(1) + (1-\pi_1)o(1)=o(1)$ as $p\to\infty$. Hence, the proof.\hfill\QEDB\newline

% {\bf Mathematical details for the results in HDLSS asymptotic regime ends here.}

{\it The following results are derived for ultrahigh-dimensional settings, where $n$ goes to infinity and $p(=p_n)$ is assumed to be an increasing function of $n$. In particular, we assume} $\log\ p_n=O(n^\beta)$ {\it for some }$0\leq \beta<1$.
\begin{lemma}\label{supplemma}
Suppose $X_n - a_0 = O_{\rm P}(a_n)$ and $Y_n - b_0 = O_{\rm P}(b_n)$ with $a_n=o(b_n)$ and $\max\{|a_0|,|b_0|\}<c_0$ for some $c_0>0$. Then
$X_nY_n - a_0b_0 = O_{\rm P}(b_n).$
\end{lemma}

\noindent {\bf Proof}:
From the triangle inequality we have
\begin{align*}
 &\ |X_nY_n - a_0b_0|\leq |X_nY_n - b_0X_n - a_0Y_n + a_0b_0| + |b_0||X_n-a_0|+|a_0||Y_n-b_0|\\
 \text{i.e., }&\ |X_nY_n - a_0b_0|\leq |X_n-a_0||Y_n - b_0| + |b_0||X_n-a_0|+|a_0||Y_n-b_0|\\
 \text{i.e., }&\ |X_nY_n - a_0b_0|\leq |X_n-a_0||Y_n - b_0| + c_0(|X_n-a_0|+|Y_n-b_0|).
\end{align*}
Therefore, $|X_n-a_0|\leq \epsilon$ and $|Y_n-b_0|\leq \epsilon$ implies that $|X_nY_n - a_0b_0|\leq \epsilon^2 + 2c_0\epsilon$. If $c_0$ is known, we can always choose $\epsilon>0$ such that $\epsilon^2 + 2c_0\epsilon\leq 3c_0\epsilon$. Hence, we get
\begin{align*}
 &\ {\rm P}[|X_n-a_0|\leq \epsilon,|Y_n-b_0|\leq \epsilon]\leq {\rm P}[|X_nY_n - a_0b_0|\leq 3c_0\epsilon]\\
 \text{i.e., }&\ {\rm P}[|X_nY_n - a_0b_0|>3c_0\epsilon]\leq {\rm P}[|X_n-a_0|\leq \epsilon] + {\rm P}[|Y_n-b_0|\leq \epsilon]\\
 \text{i.e., }&\ {\rm P}[|X_nY_n - a_0b_0|>3c_0\epsilon]\leq O(a_n) +O(b_n)\\
 \text{i.e., }&\ {\rm P}[|X_nY_n - a_0b_0|>3c_0\epsilon]\leq O(b_n),\ [\text{since } a_n = o(b_n)]\\
 \text{i.e., }&\ {\rm P}[|X_nY_n - a_0b_0|>\epsilon]\leq O(b_n).
\end{align*}
Hence, the proof.\hfill\QEDB\newline

Before proceeding to prove the rest of the results, let us define the following variables (for random samples $\rchi_1$ and $\rchi_2$ of sizes $n_1$ and $n_2$):
\begin{align}\label{compdef}
 & {T}_{11k} = \frac{1}{n_1(n_1-1)}\mathop{\sum\sum}\limits_{1\leq i\neq j\leq n_1}{h}(X_{ik},X_{jk}), \ \ {T}_{12k} =\frac{1}{n_1n_2}\sum\limits_{ i=1}^{n_1}\sum\limits_{ j=1}^{n_2}{h}(X_{ik},Y_{jk}),\nonumber \\
 & {T}_{22k} = \frac{1}{n_2(n_2-1)}\mathop{\sum\sum}\limits_{1\leq i\neq j\leq n_2}{h}(Y_{ik},Y_{jk}), \ \ T_{1k}(Z_k) = \frac{1}{n_1}\sum\limits_{i=1}^{n_1}h(X_{ik},Z_k),\nonumber \\
 & T_{2k}(Z_k) = \frac{1}{n_2}\sum\limits_{j=1}^{n_2}h(Y_{jk},Z_k),\ \  L_{1k}(Z_k) = T_{11k} - 2T_{1k}(Z_k)\text{ and }\nonumber \\
 & L_{2k}(Z_k) = T_{22k} - 2T_{2k}(Z_k)\text{ for } k=1,\ldots, p_n.
\end{align}

Now, the estimators of $\bar{\tau}_{11},\bar{\tau}_{12}$ and $\bar{\tau}_{22}$ are defined as follows:
\begin{align*}
 & \bar{T}_{11} = \frac{1}{n_1(n_1-1)p_n}\sum\limits_{k=1}^{p_n}\mathop{\sum\sum}\limits_{1\leq i\neq j\leq n_1}{h}(X_{ik},X_{jk}),\ \ \bar{T}_{12} = \frac{1}{n_1n_2 p_n}\sum\limits_{k=1}^{p_n}\sum\limits_{ i=1}^{n_1}\sum\limits_{ j=1}^{n_2}{h}(X_{ik},Y_{jk})\text{ and }\\
 & \bar{T}_{22} = \frac{1}{n_2(n_2-1)p_n}\sum\limits_{k=1}^{p_n}\mathop{\sum\sum}\limits_{1\leq i\neq j\leq n_1}{h}(Y_{ik},Y_{jk}).
\end{align*}

These estimators can be further expressed as
\begin{align*}
 {\bar{T}}_{11} = \frac{1}{p_n}\sum\limits_{k=1}^{p_n} T_{11k},\
 {\bar{T}}_{12} = \frac{1}{p_n}\sum\limits_{k=1}^{p_n} T_{12k}\text{ and }
 {\bar{T}}_{22}  = \frac{1}{p_n}\sum\limits_{k=1}^{p_n} T_{22k}.
\end{align*}
%$\bar{\mathcal{T}}$ is estimated by $\bar{T}= \bar{T}_{11} - 2\bar{T}_{12} + \bar{T}_{22}$.
Similarly, for a test observation $\bZ\in\mathbb{R}^{p_n}$, we can write
\begin{align*}
&\ \bar{T}_{1}(\bZ) = \frac{1}{p_n}\sum\limits_{k=1}^{p_n}T_{1k}(Z_k),\ \text{and } \bar{T}_{2}(\bZ) = \frac{1}{p_n}\sum\limits_{k=1}^{p_n}T_{2k}(Z_k).
\end{align*}
Recall the definitions of $\bar{L}_1(\bZ),\bar{L}_2(\bZ)$ and $\theta(\bZ)$ given in Eq. \eqref{ref6}. Lemma 3.4 gives upper bounds on the rates of convergence of these random variables. \newline

We now state the bounded differences inequality that will be used to derive the concentration bounds.

Given vectors $\bx,\bx^\prime\in\mathbb{R}^n$ and an index $l\in\{1,\ldots,n\}$, we define a new vector $\bx^{\backslash l}\in\mathbb{R}^n$ as
\begin{align}\label{bdddiffprop}
 \bx^{\backslash l}=\begin{cases}
x_j,& \text{if } j\neq l,\\
x^{\prime}_l, &           \text{if } j= l.
\end{cases}
\end{align}
With this notation, we say that $f:\mathbb{R}^n\to\mathbb{R}$ satisfies the bounded difference inequality with parameters $(M_1,\ldots, M_n)$ if
$$|f(\bx)-f(\bx^{\backslash l})|\leq M_l\text{ for each }l=1,\ldots,n,\text{ for all }\bx,\bx^\prime\in\mathbb{R}^n.$$

\begin{lemma}\label{bdddiffineq}
\citep[page 37]{wainwright2019high} Suppose that $f$ satisfies the bounded difference property \eqref{bdddiffprop} with parameters $(M_1,\ldots, M_n)$ and that the random vector $\bU = (U_1,\ldots, U_n)^\top$ has independent components. Then,
$${\rm P}\left[\left|f(\bU)-{\rm E}[f(\bU)]\right|>\epsilon\right ]\leq 2e^{-\frac{2\epsilon^2}{\sum_{l=1}^nM_l^2}}\text{ for all }\epsilon>0.$$
\end{lemma}

Using Lemma \ref{bdddiffineq}, we first derive the rates of convergence of $\bar{T}_{ij}$ and $\bar{T}_i(\bZ)$ for $i,j\in\{1,2\}$.
\begin{lemma}\label{supplemm2}
Fix $0<\gamma<1/2$. Then, there exists positive constants $a_{ij},b_{i}$ for $i,j\in\{1,2\}$ such that
\begin{enumerate}[(a)]
 \item ${\rm P}\big [|\bar{T}_{ij}-\bar{\tau}_p(i,j)|>n^{-\gamma} \big]\leq O(p_n e^{-a_{ij} n^{1-2\gamma}})$ and
 \item ${\rm P}\big [|\bar{T}_{i}(\bZ)-E[\bar{T}_{i}(\bZ)\mid \bZ]|>n^{-\gamma} \mid \bZ]\leq O(p_n e^{-b_{i} n^{1-2\gamma}})\text{ for }i,j\in\{1,2\}$.
\end{enumerate}
\end{lemma}

\noindent {\bf Proof of Lemma \ref{supplemm2}}
\begin{enumerate}[(a)]
 \item Fix $k\in\{1,\ldots,p_n\}$. Recall the definitions of ${T}_{11k},{T}_{22k}$ and ${T}_{12k}$ in Eq. \eqref{compdef} and note that the first two random variables are one sample U-statistics with kernel $h$ (of order 2), while the third random variable is a two sample U-statistic with kernel $h$ (of order (1,1)).

The random vector $\mathcal{X}_k=(X_{1k},\ldots,X_{n_1k})^\top$ has independent components. Since $|h|\leq 1$, Lemma \ref{bdddiffineq} can be used to estalish the concentration of $T_{11k}$ around its mean. Viewing $T_{11k}$ as a function $f(X_{1k},\ldots,X_{n_1k})$, for any given coordinate $l\in\{1,\ldots, n_1\}$, we have
\begin{align*}
 |f(\mathcal{X}_k)-f(\mathcal{X}_k^{\backslash l})|&\leq \frac{2}{n_1(n_1-1)}\sum\limits_{j\neq l}|h(X_{jk},X_{lk})-h(X_{jk},X^\prime_{lk})|\leq 2(n_1-1)\frac{2}{n_1(n_1-1)}=\frac{4}{n_1}.
\end{align*}
So, the bounded difference property holds with parameter $M_l=4/n_1$ in each coordinate. We now conclude that
\begin{align}\label{0X}
 {\rm P}\big [|{T}_{11k}-{\rm E}[{T}_{11k}]|>n^{-\gamma} \big]\leq 2e^{- \frac{n_1 n^{-2\gamma}}{8}}.
\end{align}
Since $\lim_{n\to\infty}n_1/n=\pi_1<1$, there exist  constants $a_{11}>0$ and $N\in\mathbb{N}$ such that
\begin{align}\label{1X}
 P[|{T}_{11k} - {\rm E}[{T}_{11k}]|\geq n^{-\gamma}]\leq 2e^{-{a_{11} n^{1-2\gamma}}}\text{ for all }n\geq N.
\end{align}
Clearly, Eq. \eqref{1X} is true for all $k=1,\ldots, p_n$, i.e.,
\begin{align}\label{ref11}
 &\ P[|{T}_{11k} - {\rm E}[ {T}_{11k}]|\geq n^{-\gamma}]\leq O(e^{-{a_{11} n^{1-2\gamma}}})\text{ for all }k=1,\ldots,p_n\nonumber \\
 \text{i.e., }&\ \sum\limits_{k=1}^{p_n}P[|{T}_{11k} - {\rm E}[ {T}_{11k}]|\geq n^{-\gamma}]\leq O(p_n e^{-{a_{11} n^{1-2\gamma}}})\nonumber \\
 \text{i.e., }&\ P\bigg [\frac{1}{p_n}\sum\limits_{k=1}^{p_n}|{T}_{11k} - {\rm E}[ {T}_{11k}]|\geq n^{-\gamma} \bigg]\leq O(p_n e^{-{a_{11} n^{1-2\gamma}}})\nonumber \\
 \text{i.e., }&\ P\bigg [\bigg |\frac{1}{p_n}\sum\limits_{k=1}^{p_n}({T}_{11k} - {\rm E}[ {T}_{11k}])\bigg |\geq n^{-\gamma} \bigg]\leq O(p_n e^{-{a_{11} n^{1-2\gamma}}})\nonumber \\
 \text{i.e., }&\ P \left [ \left |\bar{T}_{11} - \bar{\tau}_p(1,1)) \right |\geq n^{-\gamma} \right ]\leq O(p_n e^{-{a_{11} n^{1-2\gamma}}})\ \left [\text{since }\sum_{k=1}^{p_n}{\rm E}[ {T}_{11k}]/p_n = \bar{\tau}_{p_n}(1,1)\right ].
\end{align}

Following similar arguments, it can be shown that there exist positive constants $a_{12}$ and $a_{22}$ such that
\begin{align}\label{ref12}
{\rm P}\big [|\bar{T}_{12}-\bar{\tau}_p(1,2)|>n^{-\gamma} \big]\leq O(p_n e^{-a_{12} n^{1-2\gamma}})\text{ and } {\rm P}\big [|\bar{T}_{22}-\bar{\tau}_p(2,2)|>n^{-\gamma} \big]\leq O(p_n e^{-a_{22} n^{1-2\gamma}}).
\end{align}

 \item Recall the definition of $\bar{T}_{1}(\bz)$ in \eqref{} and observe that for each $\bz\in\mathbb{R}^{p_n}$ we have the following:
 \begin{align}\label{nref5}
    &\  {\rm P}\left [|\bar{T}_{1}(\bz)-E[\bar{T}_{1}(\bz)]|>n^{-\gamma} \right ]\nonumber \\
     = &\  {\rm P}\left [\left |\frac{1}{p_n}\sum\limits_{k=1}^{p_n}T_{1k}(z_k)-\frac{1}{p_n}\sum\limits_{k=1}^{p_n}E[T_{1k}(z_k)]\right |>n^{-\gamma}\right ]\nonumber \\
     \leq &\  {\rm P}\left [\frac{1}{p_n}\sum\limits_{k=1}^{p_n}\left |T_{1k}(z_k)-E[T_{1k}(z_k)]\right |>n^{-\gamma} \right ]\nonumber \\
     \leq &\  \sum\limits_{k=1}^{p_n}{\rm P}\left [\left |T_{1k}(z_k)-E[T_{1k}(z_k)]\right |>n^{-\gamma} \right ]\nonumber \\
     \leq &\  \sum\limits_{k=1}^{p_n}{\rm P}\left [\left |\frac{1}{n_1}\sum\limits_{i=1}^{n_1}h(X_{ik},z_k)-\frac{1}{n_1}\sum\limits_{i=1}^{n_1}E[h(X_{ik},z_k)]\right |>n^{-\gamma}\right ]\nonumber \\
     = &\  \sum\limits_{k=1}^{p_n}{\rm P}\left [\left |\frac{1}{n_1}\sum\limits_{i=1}^{n_1}\left \{ h(X_{ik},z_k)-E[h(X_{ik},z_k)]\right \}\right |>n^{-\gamma}\right ].
\end{align}
Note that $\sum_{i=1}^{n_1}h(X_{ik},z_k)/n_1$ is an average of independently distributed random variables for each $\bz\in\mathbb{R}^{p_n}$. Therefore, for every $\bz$, the following holds true due to the Hoeffding's inequality:
\begin{align}\label{nref6}
    &\ P\left [\left |\frac{1}{n_1} \sum_{i=1}^{n_1}\left \{h(X_{ik},z_k) - E[h(X_{ik},z_k)]\right \}\right |> n^{-\gamma}\right ]\leq \ 2e^{-n_1n^{-2\gamma}}\text{ for all }1\leq k\leq p_n,\nonumber \\
    \text{i.e., }&\ \sum\limits_{k=1}^{p_n} P\left [\left |\frac{1}{n_1} \sum_{i=1}^{n_1}\left \{ h(X_{ik},z_k) - E[h(X_{ik},z_k)]\right \}\right |> n^{-\gamma}\right ]\leq \ 2p_ne^{-n_1n^{-2\gamma}},\nonumber \\
    \text{i.e., }&\ \sum\limits_{k=1}^{p_n} P\left [\left |\frac{1}{n_1} \sum_{i=1}^{n_1}\left \{ h(X_{ik},z_k) - E[h(X_{1k},z_k)]\right \}\right |> n^{-\gamma}\right ]\leq O(p_n e^{-b_1n^{1-2\alpha_0}})\text{ for some }b_1>0.
\end{align}
Combining \eqref{nref5} and \eqref{nref6}, for every $\bz\in\mathbb{R}^{p_n}$ we get
\begin{align*}
&\ {\rm P}\left [|\bar{T}_{1}(\bz)-E[\bar{T}_{1}(\bz)]|>n^{-\gamma} \right ]\leq O(p_n e^{-b_1 n^{1-2\alpha_0}})\text{ for some }b_1>0,\\
 \text{i.e., }&{\rm P}\left [|\bar{T}_{1}(\bZ)-E[\bar{T}_{1}(\bZ)\mid \bZ]|>n^{-\gamma} \mid \bZ\right ]\leq O(p_n e^{-b_1 n^{1-2\alpha_0}})\text{ for some }b_1>0.
\end{align*}
Similarly, one can show that there exists a constant $b_2>0$ such that
$${\rm P}\left [|\bar{T}_{2}(\bZ)-E[\bar{T}_{2}(\bZ)\mid \bZ]|>n^{-\gamma} \mid \bZ\right ]\leq O(p_n e^{-b_2 n^{1-2\alpha_0}}).$$
\end{enumerate}
Hence, the proof.\hfill\QEDB\newline

\noindent {\bf Proof of Lemma 3.4}
For any $0<\gamma<1/2$, we consider
 \begin{align}\label{ref14}
 &\ {\rm P}\big [|\bar{L}_2(\bZ)- \bar{L}_1(\bZ) - \bar{\tau}_{p_n}|>n^{-\gamma}\mid \bZ\sim\bF_1\big ]\nonumber \\
 =&\ {\rm P}\big [|\{\bar{T}_{22} - 2\bar{T}_2(\bZ)- \bar{T}_{11} + 2\bar{T}_1(\bZ)\}
 - \{\bar{\tau}_{p_n}(1,1) - 2\bar{\tau}_{p_n}(1,2) +\bar{\tau}_{p_n}(2,2)\}|>n^{-\gamma}\mid \bZ\sim\bF_1\big ]\nonumber \\
 \leq &\ {\rm P}\big [|\{\bar{T}_{22} - 2\bar{T}_2(\bZ)- \bar{T}_{11} + 2\bar{T}_1(\bZ)\}- \{2\bar{\tau}_{p_n}(1,1) -\bar{\tau}_{p_n}(1,1) - 2\bar{\tau}_{p_n}(1,2) +\bar{\tau}_{p_n}(2,2)\}|>n^{-\gamma}\mid \bZ\sim\bF_1\big ]\nonumber \\
 \leq &\ {\rm P}\left [|\bar{T}_{11}-\bar{\tau}_{p_n}(1,1)|>\frac{n^{-\gamma}}{4}\right ] + {\rm P}\left [|\{\bar{T}_{22} - \bar{\tau}_{p_n}(2,2)|>\frac{n^{-\gamma}}{4}\right ]\nonumber \\
 &\ \ + {\rm P}\left [2|\bar{T}_2(\bZ)- \bar{\tau}_{p_n}(1,2)|>\frac{n^{-\gamma}}{4}\mid \bZ\sim\bF_1\right ]+ {\rm P}\left [2\left |\bar{T}_1(\bZ) - \bar{\tau}_{p_n}(1,1)\right |>\frac{n^{-\gamma}}{4}\mid \bZ\sim\bF_1\right ]
\end{align}
From Lemma \ref{supplemm2}, we have a positive constant $B_0(a_{11},a_{22},b_1,b_2)$ such that the right hand side of Eq. \eqref{ref14} is $O(p_ne^{-B_0n^{1-2\gamma}})$ as $n\to\infty$. Hence,
$${\rm P}\big [|\bar{L}_2(\bZ)- \bar{L}_1(\bZ) - \bar{\tau}_{p_n}|>n^{-\gamma}\mid \bZ\sim\bF_1\big ]\leq O(p_ne^{-B_0n^{1-2\gamma}})\text{ as }n\to\infty.$$

Now, we derive a concentration bound for $\theta(\bZ)$. From \eqref{ref6} we, have $$\theta(\bZ) = \frac{1}{2}\big \{(\bar{T}_{11}-2\bar{T}_{12}+\bar{T}_{22})\times S_1(\bZ)\big \}
 +\frac{1}{2}\big \{(\bar{T}_{22}-\bar{T}_{11})\times S_2(\bZ)\big \},$$
 where $S_1(\bZ) = \bar{T}_{22} - 2\bar{T}_2(\bZ) - \bar{T}_{11} + 2\bar{T}_1(\bZ)$ and $S_2(\bZ) = \bar{T}_{22} - 2\bar{T}_2(\bZ) + \bar{T}_{11} - 2\bar{T}_1(\bZ)+2\bar{T}_{12}$. We already have
 \begin{align*}
  {\rm E}[\bar{T}_{11}-2\bar{T}_{12}+\bar{T}_{22}]=\bar{\tau}_{p_n}\text{ and }{\rm E}[\bar{T}_{22}-\bar{T}_{11}]=\bar{\tau}_{p_n}(2,2)-\bar{\tau}_{p_n}(1,1).
 \end{align*}
Also, note that
 \begin{align*}
  &{\rm E}[S_1(\bZ)\mid\bZ\sim\bF_1]=\bar{\tau}_{p_n},\ {\rm E}[S_2(\bZ)\mid\bZ\sim\bF_1]=\bar{\tau}_{p_n}(2,2)-\bar{\tau}_{p_n}(1,1),\\
  &{\rm E}[S_1(\bZ)\mid\bZ\sim\bF_2]=-\bar{\tau}_{p_n}\text{ and } {\rm E}[S_2(\bZ)\mid\bZ\sim\bF_2]=-\{\bar{\tau}_{p_n}(2,2)-\bar{\tau}_{p_n}(1,1)\}.
 \end{align*}
It clearly follows from Lemma \ref{supplemm2} that there exist positive constants $c_4, c_5$ such that
\begin{align}\label{ref16}
 &\ {\rm P}\big [|\{\bar{T}_{11}-2\bar{T}_{12}+\bar{T}_{22}\}- \bar{\tau}_{p_n}|>n^{-\gamma}\big ]\leq O(p_ne^{-c_4 n^{1-2\gamma}})\text{ and }\nonumber \\
 &\
 {\rm P}\big [|\{\bar{T}_{22}-\bar{T}_{11}\}- \{\bar{\tau}_{p_n}(2,2)-\bar{\tau}_{p_n}(1,1)\}|>n^{-\gamma}\big ]\leq O(p_ne^{-c_5 n^{1-2\gamma}})\text{ as }n\to\infty.
\end{align}
Lemma \ref{supplemm2} also suggests that there exist positive constants $c_6,c_7,c_8$ and $c_9$ such that
\begin{align}\label{ref17}
 &{\rm P}\big [|S_1(\bZ)-\bar{\tau}_{p_n}|>n^{-\gamma}\mid \bZ\sim\bF_1\big ]\leq O(p_ne^{-c_6 n^{1-2\gamma}}),\nonumber \\
 & {\rm P}\big [|S_2(\bZ)-\{\bar{\tau}_{p_n}(2,2)-\bar{\tau}_{p_n}(1,1)\}|z>n^{-\gamma} \mid \bZ\sim\bF_1\big ]\leq O(p_ne^{-c_7 n^{1-2\gamma}}),\nonumber \\
 &{\rm P}\big [|S_1(\bZ)+\bar{\tau}_{p_n}|>n^{-\gamma}\mid \bZ\sim\bF_2\big ]\leq O(p_ne^{-c_8 n^{1-2\gamma}})\text{ and }\nonumber \\
 & {\rm P}\big [|S_2(\bZ)+\{\bar{\tau}_{p_n}(2,2)- \bar{\tau}_{p_n}(1,1)\}|>n^{-\gamma}\mid \bZ\sim\bF_2\big ]\leq O(p_ne^{-c_9 n^{1-2\gamma}})\text{ as }n\to\infty.
\end{align}
Now,
\begin{align}\label{ref18}
 &\ {\rm P}\big [|\theta(\bZ) - \bar{\psi}_{p_n}|>\epsilon \mid \bZ\sim\bF_1 \big]\nonumber \\
 =&\ {\rm P}\left [\left |\theta(\bZ) - \left \{\frac{1}{2}\bar{\tau}^2_{p_n} + \frac{1}{2}(\bar{\tau}_{p_n}(2,2)-\bar{\tau}_{p_n}(1,1))^2\right \}\right |>\epsilon \mid \bZ\sim\bF_1 \right ]\nonumber \\
 \leq &\ {\rm P}\bigg [\bigg |\frac{1}{2}\left \{(\bar{T}_{11}-2\bar{T}_{12}+\bar{T}_{22})\times S_1(\bZ)\right \}
 +\frac{1}{2}\big \{(\bar{T}_{22}-\bar{T}_{11})\times S_2(\bZ)\big \}\nonumber \\
 &\hspace{1in} - \left \{\frac{1}{2}\bar{\tau}_{p_n}^2 + \frac{1}{2}(\bar{\tau}_{p_n}(2,2)-\bar{\tau}_{p_n}(1,1))^2\right \}\bigg |>\epsilon \mid \bZ\sim\bF_1 \bigg]\nonumber \\
 \leq &\ {\rm P}\big [\big |(\bar{T}_{11}-2\bar{T}_{12}+\bar{T}_{22})\times S_1(\bZ) - \tau^2_{p_n}\big |>\epsilon \mid \bZ\sim\bF_1 \big]\nonumber \\
 &\hspace{1in}+{\rm P}\left [\big |(\bar{T}_{22}-\bar{T}_{11})\times S_2(\bZ) - (\bar{\tau}_{p_n}(2,2)-\bar{\tau}_{p_n}(1,1))^2\big |>\epsilon \mid \bZ\sim\bF_1 \right].
\end{align}

% Observe that $0\leq \bar{\tau}_{p_n}\leq 4$, and $0\leq |\bar{\tau}_{p_n}(1,1)-\bar{\tau}_{p_n}(2,2)|\leq 2$.
Combining Eqs. \eqref{ref16} and \eqref{ref17} with Lemma \ref{supplemma}, we can conclude that there exists a constant $c_{10}$ such that
\begin{align}\label{E1}
 {\rm P}\big [\big |(\bar{T}_{11}-2\bar{T}_{12}+\bar{T}_{22})\times S_1(\bZ) - \tau^2\big |>\epsilon \mid \bZ\sim\bF_1 \big]\leq O(p_n e^{-c_{10} n\epsilon^2})\text{ as }n\to\infty.
\end{align}

Similarly, there exists a constant $c_{11}>0$ such that
\begin{align}\label{E2}
 {\rm P}\big [\big |(\bar{T}_{22}-\bar{T}_{11})\times S_2(\bZ) - (\bar{\tau}_{p_n}(2,2)-\bar{\tau}_{p_n}(1,1))^2\big |>\epsilon \mid \bZ\sim\bF_1 \big]\leq O(p_n e^{-c_{11} n\epsilon^2})\text{ as }n\to\infty.
\end{align}
Define $B_2 = \min\{c_{10},c_{11}\}$. Then, it follows from Eqs. \eqref{E1} and \eqref{E2} that $${\rm P}\big [|\theta(\bZ) - \bar{\psi}_{p_n}|>\epsilon \mid \bZ\sim\bF_1 \big]\leq O(p_n e^{-B_2 n\epsilon^2})\text{ as }n\to\infty.$$
\hfill \QEDB\newline

\noindent {\bf Proof of Theorem 3.5}

From the definition of $\Delta_1$, we have
\begin{align}\label{misclass1}
\Delta_1 = {\rm P}[\delta_1(\bZ)\neq \text{ true label of }\bZ]
 =&\ \pi_1 {\rm P}[\delta_1(\bZ)=2\mid \bZ\sim\bF_1] + (1-\pi_1){\rm P}[\delta_1(\bZ)=1\mid \bZ\sim\bF_2]\nonumber \\
 =&\ \pi_1 {\rm P}[\bar{L}_2(\bZ)\leq \bar{L}_1(\bZ)\mid \bZ\sim\bF_1]+ (1-\pi_1){\rm P}[\bar{L}_2(\bZ)> \bar{L}_1(\bZ)\mid \bZ\sim\bF_2].
\end{align}
Since A3 is satisfied for $0<\alpha<(1-\beta)/2<1/2$, we have $N\in \mathbb{N}$ such that $n^{-\alpha} <\bar{\tau}_{p_n}$ for all $n\geq N$. Therefore,
\begin{align}\label{ref15}
{\rm P}\big [\bar{L}_2(\bZ)\leq \bar{L}_1(\bZ)\mid \bZ\sim\bF_1\big ]
&\ \leq {\rm P}\big [\bar{L}_2(\bZ)- \bar{L}_1(\bZ)\leq \bar{\tau}_{p_n}-n^{-\alpha}\mid \bZ\sim\bF_1\big ]\text{ for all }n\geq N\nonumber \\
\text{i.e., }{\rm P}\big [\bar{L}_2(\bZ)\leq \bar{L}_1(\bZ)\mid \bZ\sim\bF_1\big ]&\ \leq {\rm P}\big [|\bar{L}_2(\bZ)- \bar{L}_1(\bZ) - \bar{\tau}_{p_n}|>n^{-\alpha}\mid \bZ\sim\bF_1\big ]\text{ for all }n\geq N.
\end{align}
Now, it follows from Lemma 3.4 that ${\rm P}\big [\bar{L}_2(\bZ)\leq \bar{L}_1(\bZ)\mid \bZ\sim\bF_1\big ]\leq O(p_ne^{-B_0n^{1-2\alpha}})$. Since $\log\ p_n =O(n^\beta)$ for some $0\leq \beta<1$, we have $M>0$ and $N_1\in\mathbb{N} $ such that
\begin{align*}
 &\ \log\ p_n\leq Mn^\beta \text{ for all } n\geq N_1,\\
 \text{i.e., }&\ p_n e^{-B_0n^{1-2\alpha}}\leq e^{-B_0n^{1-2\alpha} + M n^\beta}\text{ for all } n\geq N_1.
\end{align*}
Note that $e^{-B_0n^{1-2\alpha} + M n^\beta}=O(e^{-B_2\{n^{1-2\alpha} - n^\beta\}})$ as $n\to\infty$ for $B_2\in (0,B_0)$. Therefore,
$${\rm P}\big [\bar{L}_2(\bZ)\leq \bar{L}_1(\bZ)\mid \bZ\sim\bF_1\big ]\leq O(p_ne^{-B_0n^{1-2\alpha}})=O(e^{-B_2\{n^{1-2\alpha} - n^\beta\}})\text{ as }n\to\infty.$$
Following similar arguments, we obtain
${\rm P}\big [\bar{L}_2(\bZ)> \bar{L}_1(\bZ)\mid \bZ\sim\bF_2\big ]=O(e^{-B_2\{n^{1-2\alpha} - n^\beta\}})$ as $n\to\infty$. Therefore, it follows from Eq. \eqref{misclass1} that
$$\Delta_1 \leq  O(e^{-B_2\{n^{1-2\alpha} - n^\beta\}})\text{ as }n\to\infty.$$
Furthermore, $\alpha<(1-\beta)/2$ implies that $e^{-B_2\{n^{1-2\alpha} - n^\beta\}}=o(1)$ as $n\to\infty$, i.e., $\Delta_1=o(1)$ as $n\to\infty$.\hfill\QEDB\newline

\noindent {\bf Proof of Theorem 3.6}

The misclassfication probability of $\delta_2$ is given by
\begin{align}\label{misclass2}
 \Delta_2 = {\rm P}[\delta_2(\bZ)\neq \text{ true label of }\bZ]
 =&\ \pi_1 {\rm P}[\theta(\bZ)\leq 0\mid \bZ\sim\bF_1]+ (1-\pi_1){\rm P}[\theta(\bZ)> 0\mid \bZ\sim\bF_2].
\end{align}
Since A3 is satisfied for $0<\alpha<(1-\beta)/2$, we have $N\in \mathbb{N}$ such that
\begin{align}\label{ref19}
 &\ \bar{\tau}_{p_n} > n^{-\alpha}\text{ for all }n\geq N\nonumber \\
 \text{i.e., }&\ \bar{\tau}^2_{p_n}> n^{-2\alpha}\text{ for all }n\geq N\nonumber \\
 \text{i.e., }&\ \frac{1}{2}\bar{\tau}^2_{p_n} + \frac{1}{2}\big (\bar{\tau}_{p_n}(1,1) - \bar{\tau}_{p_n}(2,2)\big )^2> \frac{n^{-2\alpha}}{2}\text{ for all }n\geq N\nonumber \\
 \text{i.e., }&\ \bar{\psi}_{p_n}> \frac{n^{-2\alpha}}{2}\text{ for all }n\geq N.
\end{align}

Therefore,
\begin{align*}
&\ {\rm P}\big [\theta(\bZ)\leq 0\mid \bZ\sim\bF_1\big ]\leq {\rm P}\left [\theta(\bZ)\leq \bar{\psi}_{p_n}-\frac{n^{-2\alpha}}{2} \big | \bZ\sim\bF_1\right ]\leq {\rm P}\left [|\theta(\bZ) - \bar{\psi}_{p_n}|>\frac{n^{-2\alpha}}{2}\big | \bZ\sim\bF_1\right ]\text{ for all }n\geq N\\
\text{i.e., }&\  {\rm P}\big [\theta(\bZ)\leq 0\mid \bZ\sim\bF_1\big ]\leq O(p_ne^{-\frac{1}{4}B_1n^{1-4\alpha}})\text{ as }n\to\infty\ [\text{following  Lemma }3.4]\\
\text{i.e., }&\  {\rm P}\big [\theta(\bZ)\leq 0\mid \bZ\sim\bF_1\big ]\leq O(e^{-B_3\{n^{1-4\alpha}- n^{\beta}\}})\text{ as }n\to\infty\ [\text{for }B_3\in (0,B_1/4)].
\end{align*}
Similarly, ${\rm P}\big [\theta(\bZ)> 0\mid \bZ\sim\bF_2\big ]
\leq O(e^{-B_3\{n^{1-4\alpha}- n^{\beta}\}})$ as $n\to\infty$. Therefore, it follows from Eq. \eqref{misclass2} that $\Delta_2\leq O(e^{-B_3\{n^{1-4\alpha}- n^{\beta}\}})$ as $n\to\infty$. Furthermore, $\alpha<(1-\beta)/4$ implies that $e^{-B_3\{n^{1-4\alpha} - n^\beta\}}=o(1)$ as $n\to\infty$, i.e., $\Delta_2=o(1)$ as $n\to\infty$.\hfill\QEDB\newline



\begin{lemma}\label{asconv}
If A1 and A2 are satisfied for $0<\alpha_1<(1-\beta)/2$ and $0<\alpha_2<(1-\beta)/2,$ respectively, then there exists a positive constant $C_6$ such that  $$P[|\hat{\xi}^\gamma_n(\bZ)-\xi(\bZ)|>n^{-\alpha_0}]\leq O(e^{-C_6\{n^{1-2\alpha_0}-n^{\beta}\}})\text{ where }\alpha_0=\max\{\alpha_1,\alpha_2\}.$$
\end{lemma}
{\bf Proof of Lemma \ref{asconv} :}
\noindent{\bf Proof of Theorem \ref{thmclass}:} Let $l_{\bZ}$ denote the true class label of $\bZ,$ i.e., $\bZ\mid l_{\bZ}=1\sim\bF$ and $\bZ\mid l_{\bZ}=2\sim\bG$ where $P[l_{\bZ}=i]=\pi_i$ with $\pi_1+\pi_2=1.$ We denote the unconditional distribution of $\bZ$ by $\bH(\bz) = \pi_1\bF(\bz) + \pi_2\bG(\bz)$ for $\bz\in\mathbb{R}^{d_n}.$ The misclassification probabilities of $\delta_{0}$ and $\delta_{gSAVG}$ are defined as $\Delta_0 = P[\delta_{0}(\bZ)\neq l_{\bZ}]\text{ and } \Delta_{gSAVG} = P[\delta_{gSAVG}(\bZ)\neq l_{\bZ}],\text{ respectively.}$ Now, observe that %We will show that $\Delta_{gSAVG} - \Delta_{0}$ goes to 0 as $n\to\infty$.
\begin{align}\label{nref11}
    &\ \Delta_{gSAVG} - \Delta_{0}\nonumber \\
    =&\ P[\delta_{gSAVG}(\bZ)\neq l_{\bZ}]- P[\delta_{0}(\bZ)\neq l_{\bZ}]\nonumber\\
    =&\ \int \left \{P[\delta_{gSAVG}(\bz)\neq l_{\bz}\mid \bz]- P[\delta_{0}(\bz)\neq l_{\bz}\mid \bz]\right \}\ d\bH(\bz)\nonumber\\
    =&\ \int \left \{P[\delta_{0}(\bz)= l_{\bz}\mid \bz]- P[\delta_{gSAVG}(\bz)= l_{\bz}\mid \bz]\right\}\ d\bH(\bz)\nonumber\\
    =&\ \int \big \{\big (I[\delta_{0}(\bz)=1]P[ l_{\bz}=1\mid \bz] + I[\delta_{0}(\bz)=0]P[ l_{\bz}=0\mid \bz]\big )-\nonumber\\ 
    &\ \ \big (P[\delta_{gSAVG}(\bz)=1]P[ l_{\bz}=1\mid \bz] + P[\delta_{gSAVG}(\bz)=0]P[ l_{\bz}=0\mid \bz]\big)\big \}\ d\bH(\bz)\nonumber\\
    =&\ \int \big \{(I[\delta_{0}(\bz)=1] - P[\delta_{gSAVG}(\bz)=1])P[ l_{\bz}=1\mid \bz] +\nonumber\\
    &\ \ (I[\delta_{0}(\bz)=0] - P[\delta_{gSAVG}(\bz)=0])P[ l_{\bz}=0\mid \bz]\big \}\ d\bH(\bz)\nonumber\\
    =&\ \int (I[\delta_{0}(\bz)=1] - E\big [I[\delta_{gSAVG}(\bz)=1]\big ])(2P[ l_{\bz}=1\mid \bz]-1)\ d\bH(\bz)\nonumber\\
    \leq &\ \int \big |E\big [I[\delta_{0}(\bz)=1] - I[\delta_{gSAVG}(\bz)=1]\big ]\big |\ |2P[ l_{\bz}=1\mid \bz]-1|\ d\bH(\bz)\nonumber\\
    = &\ \int E\big [|I[\delta_{0}(\bz)=1] - I[\delta_{gSAVG}(\bz)=1]|\big ]\ d\bH(\bz)\nonumber\\
    = &\ \int E\big [I[\delta_{0}(\bz)\neq \delta_{gSAVG}(\bz)]\big ]\ d\bH(\bz)\nonumber\\
    = &\ \int P[\delta_{0}(\bz)\neq \delta_{gSAVG}(\bz)]\ d\bH(\bz)\nonumber\\
    = &\ \int \left \{P[\delta_{0}(\bz)\neq \delta_{gSAVG}(\bz), \hat{S}_n=S_n] + P[\delta_{0}(\bz)\neq \delta_{gSAVG}(\bz), \hat{S}_n\neq S_n]\right \}\ d\bH(\bz)\nonumber\\
    %= &\ \int \Big \{P[\delta_{0}(\bz)\neq \delta_{gSAVG}(\bz)\mid \hat{S}_n=S_n]P[\hat{S}_n=S_n] +\nonumber\\
    %&\hspace{1cm} P[\delta_{0}(\bz)\neq \delta_{gSAVG}(\bz)\mid  \hat{S}_n\neq S_n]P[ \hat{S}_n\neq S_n]\Big \}\ d\bH(\bz)\nonumber\\
    \leq  &\ \int \left \{ P[\delta_{0}(\bz)\neq \delta_{gSAVG}(\bz), \hat{S}_n=S_n] +P[\hat{S}_n\neq S_n]\right \}\ d\bH(\bz)\nonumber\\
    = &\ \int P[\delta_{0}(\bz)\neq \delta_{gSAVG}(\bz), \hat{S}_n=S_n]\ d\bH(\bz) +P[\hat{S}_n\neq S_n]\nonumber\\
    = &\ \int P[\xi^\gamma_1(\bz)-\xi^\gamma_2(\bz)>0,\hat{\xi}^\gamma_{1n}(\bz)-\hat{\xi}^\gamma_{2n}(\bz)\leq 0, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    &\ +\ \int P[\xi^\gamma_1(\bz)-\xi^\gamma_2(\bz)\leq 0,\hat{\xi}^\gamma_{1n}(\bz)-\hat{\xi}^\gamma_{2n}(\bz)> 0, \hat{S}_n=S_n]\ d\bH(\bz)+P[\hat{S}_n\neq S_n]\nonumber\\
    =&\ P_1 + P_2 + P[\hat{S}_n\neq S_n].
\end{align}
Define $\xi^\gamma(\bz) = \xi^\gamma_1(\bz)-\xi^\gamma_2(\bz)$ and $\hat{\xi}^\gamma_{n}(\bz) = \hat{\xi}^\gamma_{1n}(\bz)-\hat{\xi}^\gamma_{2n}(\bz)$. Recall that $\alpha_0=\max\{\alpha_1,\alpha_2\}$ satisfies A1. We have the following:
\begin{align}\label{nref12}
    P_1 &= \int P[\xi^\gamma(\bz)>0,\hat{\xi}^\gamma_{n}(\bz)\leq 0, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    &= \int P[\xi^\gamma(\bz)>0,\hat{\xi}^\gamma_{n}(\bz)\leq 0, |\xi^\gamma(\bz)-\hat{\xi}^\gamma_{n}(\bz)|\leq n^{-\alpha_0}, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    &\ +\ \int P[\xi^\gamma(\bz)>0,\hat{\xi}^\gamma_{n}(\bz)\leq 0, |\xi^\gamma(\bz)-\hat{\xi}^\gamma_{n}(\bz)|> n^{-\alpha_0}, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    &\leq \int P[\xi^\gamma(\bz)>0,\hat{\xi}^\gamma_{n}(\bz)\leq 0, \xi^\gamma(\bz)-\hat{\xi}^\gamma_{n}(\bz)\leq n^{-\alpha_0}, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    &\ +\ \int P[|\xi^\gamma(\bz)-\hat{\xi}^\gamma_{n}(\bz)|> n^{-\alpha_0}, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    &= P_{11}(\alpha_0) + P_{12}(\alpha_0).
\end{align}
Note that 
\begin{align}\label{nref13}
    P_{11}(\alpha_0) =& \int P[\xi^\gamma(\bz)-\hat{\xi}^\gamma_{n}(\bz)\leq n^{-\alpha_0}, \xi^\gamma(\bz)>0,\hat{\xi}^\gamma_{n}(\bz)\leq 0, \hat{S}_n=S_n]\nonumber\\
    %&\ \times P[\xi^\gamma(\bz)>0,\hat{\xi}^\gamma_{n}(\bz)\leq 0\mid  \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    %\leq & \int P[\xi^\gamma(\bz)-\hat{\xi}^\gamma_{n}(\bz)\leq n^{-\alpha_0}\mid \xi^\gamma(\bz)>0,\hat{\xi}^\gamma_{n}(\bz)\leq 0, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    \leq & \int P[\xi^\gamma(\bz)\leq n^{-\alpha_0}, \xi^\gamma(\bz)>0,\hat{\xi}^\gamma_{n}(\bz)\leq 0, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    \leq & \int P[\xi^\gamma(\bz)\leq n^{-\alpha_0}, \xi^\gamma(\bz)>0]\ d\bH(\bz)\nonumber\\
     = &\ P[0<\xi^\gamma(\bZ)\leq n^{-\alpha_0}].
\end{align}
Combining \eqref{nref12} and \eqref{nref13} we observe that 
\begin{align}\label{nrefP1}
    P_1 \leq P[0<\xi^\gamma(\bZ)\leq n^{-\alpha_0}] + P_{12}(\alpha_0).
\end{align}

Following similar arguments, we can write $P_2$ as 
\begin{align}\label{nrefP2}
    P_2 &= \int P[\xi^\gamma(\bz)\leq 0,\hat{\xi}^\gamma_{n}(\bz)> 0, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    %&= \int P[\xi^\gamma(\bz)>0,\hat{\xi}^\gamma_{n}(\bz)\leq 0, |\xi^\gamma(\bz)-\hat{\xi}^\gamma_{n}(\bz)|\leq n^{-\alpha_0}, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    %&\ +\ \int P[\xi^\gamma(\bz)>0,\hat{\xi}^\gamma_{n}(\bz)\leq 0, |\xi^\gamma(\bz)-\hat{\xi}^\gamma_{n}(\bz)|> n^{-\alpha_0}, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    &\leq \int P[\xi^\gamma(\bz)\leq 0,\hat{\xi}^\gamma_{n}(\bz)> 0, |\xi^\gamma(\bz)-\hat{\xi}^\gamma_{n}(\bz)|\leq n^{-\alpha_0}, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    &\hspace{1cm} +\ \int P[|\xi^\gamma(\bz)-\hat{\xi}^\gamma_{n}(\bz)|> n^{-\alpha_0}, \hat{S}_n=S_n]\ d\bH(\bz)\nonumber\\
    &= \int P[\xi^\gamma(\bz)\leq 0,\hat{\xi}^\gamma_{n}(\bz)> 0, |\xi^\gamma(\bz)-\hat{\xi}^\gamma_{n}(\bz)|\leq n^{-\alpha_0}, \hat{S}_n=S_n]\ d\bH(\bz) +P_{12}(\alpha_0)\nonumber\\
    &\leq \int P[\xi^\gamma(\bz)\leq 0,\hat{\xi}^\gamma_{n}(\bz)> 0, -\xi^\gamma(\bz)+\hat{\xi}^\gamma_{n}(\bz)\leq n^{-\alpha_0}, \hat{S}_n=S_n]\ d\bH(\bz) +P_{12}(\alpha_0)\nonumber\\
    &\leq \int P[-n^{\alpha_0}<\xi^\gamma(\bz)\leq 0, \hat{S}_n=S_n]\ d\bH(\bz) +P_{12}(\alpha_0)\nonumber\\
    &= P[-n^{-\alpha_0}<\xi^\gamma(\bZ)\leq 0] + P_{12}(\alpha_0).
\end{align}

Combining \eqref{nref11}, \eqref{nrefP1} and \eqref{nrefP2} we obtain
\begin{align*}
    \Delta_{gSAVG} - \Delta_0\leq P[|\xi^\gamma(\bZ)|< n^{-\alpha_0}] + 2P_{12}(\alpha_0) + P[\hat{S}_n\neq S_n].
\end{align*}
An upper bound for the second term $P_{12}(\alpha_0)$ is already given in \eqref{nref10}. Therefore, it follows from Theorem \ref{mainthm_E} and \eqref{nref10} that 
\begin{align*}
    \Delta_{gSAVG} - \Delta_0 &\leq P[|\xi^\gamma(\bZ)|< n^{-\alpha_0}] + O(e^{-C_6\{ n^{1-2\alpha_0}- n^\beta\}}) + O(e^{-b_1\{ n^{1-2\alpha_0}- n^\beta\}})\\
    &\leq P[|\xi^\gamma(\bZ)|< n^{-\alpha_0}] + O(e^{-C_6\{ n^{1-2\alpha_0}- n^\beta\}}).
\end{align*}
Hence, the proof.\hspace*{\fill}\QEDB\newline

\noindent {\bf Remark 1 :} Recall that $d_n \leq e^{Mn^\beta}$ for all $n\geq N$ for some $N\in\mathbb{N}$ where $M>0$ and $0\leq \beta<1.$ Note that if $\beta =0,$ then $d_n(=d)$ is fixed. Therefore, if $\bF_1,\bF_2$ are absolutely continuous distribution function, then $P[|\xi^\gamma(\bZ)|< n^{-\alpha_0}]\to 0$ as $n\to\infty.$ Consequently, $\Delta_{gSAVG} - \Delta_0\to 0$ as $n\to\infty.$\newline

\noindent {\bf Remark 2 :} If $\beta >0,$ then $d_n$ can grow with $n$. Under this setting, if $P[|\xi^\gamma(\bZ)|< n^{-\alpha_0}]\to 0$ and $\Delta_0\to 0$ as $n\to\infty, d_n\to \infty$ then Theorem \ref{thmclass} suggests that $\Delta_{gSAVG}\to 0$ as $n\to\infty, d_n\to \infty$.\newline
    
\noindent We now present sufficient conditions for $P[|\xi^\gamma(\bZ)|< n^{-\alpha_0}]$ and $\Delta_0$ to go to 0 as $n\to\infty, d_n\to\infty.$ We will show that under appropriate moment condition and weak dependence among the component variables, $P[|\xi^\gamma(\bZ)|< n^{-\alpha_0}]\to 0$ as $d_n\to\infty.$\newline

\noindent Recall that there exist $M>0,0<\beta<1$ and $N\in\mathbb{N}$ such that 
\begin{align*}
    &\ \log\ d_n\leq Mn^\beta\\
    \text{i.e., }&\ \log\ s_n \leq \log\ d_n - \log\ 2\leq Mn^\beta- \log\ 2\ \ [\text{since } s_n\leq d_n/2],\\
    \text{i.e., }&\ \log\ s_n \leq M_1n^\beta\ \text{ for some } M_1>M,\\
    \text{i.e., }&\ n^{-\alpha}\leq (M_1/\log\ s_n)^\frac{\alpha}{\beta}\text{ for all }\alpha>0
\end{align*}
and for all $n\geq N.$ Clearly, the above inequality holds for $\alpha_0=\max\{\alpha_1,\alpha_2\}$ where $0<\alpha_1,\alpha_2<(1-\beta)/2$ satisfy A1 and A2, respectively. We now assume the following:
\begin{itemize}
    \item[A1$^\prime$.]  There exist constants $\alpha_0\le \alpha_3\le (1-\beta)/2$ and  $N\in\mathbb{N}$ such that $\min_{k\in S_n}\mathcal{E}_k>2M_1/(\log \ s_n)^{\frac{\alpha_3}{\beta}}$ for all $n\geq N.$
\end{itemize}
Note that if A1$^\prime$ is satisfied, then A1 is also satisfied readily. A1$^\prime$ allows the minimum signal to decay to 0, but at a rate slower than $1/(\log \ s_n)^{\frac{\alpha_3}{\beta}}.$ Suppose, $\bU=(U_1\ldots, U_{d_n})^\top\sim\bF_j$ and $\bU^\prime=(U^\prime_1,\ldots, U^\prime_{d_n})^\top\sim\bF_{j^\prime}$ where $j,j^\prime\in\{1,2\}$ and $\bU,\bU^\prime$ are independently distributed. We also assume the following:
\begin{enumerate}
    \item[A3.]  $E[\gamma^2(|U_{k}-U^\prime_{k}|^2)]<C<\infty$ for all $k\in S_n.$
    \item[A4.] There exists $\alpha_0\le \alpha_4\le (1-\beta)/2$ such that $$\mathop{\sum\sum}\limits_{\substack{k,k^\prime \in S_n\\ k\neq k^\prime}}\Corr{\left(E[\gamma(|U_{k}-U^\prime_{k}|^2)\mid V_{k}],E[\gamma(|U_{k^\prime}-U^\prime_{k^\prime}|^2)\mid V_{k^\prime}]\right )}=o\left (\frac{s_n^2}{\left (\log\ s_n\right )^\frac{2\alpha_4}{\beta}}\right )\text{ for }\bV\in\{\bU,\bU^\prime\}.$$ 
\end{enumerate}
The assumption A3 is trivially satisfied if $\gamma$ is a bounded function. If the underlying components are gaussian and $\gamma$ is lipschitz continuous, then also A3 is satisfied (see Lemma \ref{U_expbound_lip} for details). Let us take a look at assumption A4 now. It is needless to say that A4 is satisfied if the component variables are independently distributed. It continues to be satisfied if an additional structure on the dependence of the components is assumed. For instance, in case of sequence data, if the components are $m$-dependent \citep{billingsley2008probability} for some fixed integer $m$, then the L.H.S. in A5 is bounded by $m(2s_n- m - 1).$ Therefore, it satisfies the assumption.
%@book{billingsley2008probability,
%  title={Probability and measure},
%  author={Billingsley, Patrick},
%  year={2008},
%  publisher={John Wiley \& Sons}
%}
\begin{lemma}\label{P0_conv}
If A1$^\prime$, A3 and A4 are satisfied, then $P[|\xi^\gamma(\bZ)|<n^{-\alpha^\prime_0}]\to 0$ as $n\to\infty$ where $\alpha^\prime_0=\max\{\alpha_0,\alpha_3,\alpha_4\}.$
\end{lemma}
\noindent{\bf Proof :} 
Recall that there exist $M_1>0,0<\beta<1$ and $N\in\mathbb{N}$ such that $\log\ s_n\leq M_1n^\beta,$ i.e., $n^{-\alpha^\prime_0}\leq (M_1/\log\ s_n)^\frac{\alpha^\prime_0}{\beta}$ for all $n\geq N.$ Therefore,
\begin{align*}
    & \ P[|\xi^\gamma(\bZ)|<n^{-\alpha^\prime_0}]\\
    \leq &\ P\left [|\xi^\gamma(\bZ)|<\left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\\
    =&\ \pi P\left [|\xi^\gamma(\bX_1)|<\left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ] + (1-\pi)P\left [|\xi^\gamma(\bY_1)|<\left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\text{ for all }n\geq N.
\end{align*}
Note that
\begin{align}\label{P0_1}
    &\ P\left [|\xi^\gamma(\bX_1)-E[\xi^\gamma(\bX_1)]|\geq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\nonumber \\
    \leq &\ P\left [|\xi_1^\gamma(\bX_1)-E[\xi_1^\gamma(\bX_1)]|\geq \frac{1}{2}\left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]+P\left [|\xi_2^\gamma(\bX_1)-E[\xi_2^\gamma(\bX_1)]|\geq \frac{1}{2}\left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\nonumber \\
    \leq &\ \frac{1}{4}\left (\frac{\log\ s_n}{M_1}\right )^\frac{2\alpha^\prime_0}{\beta}\left \{Var[\xi_1^\gamma(\bX_1)]+Var[\xi_2^\gamma(\bX_1)]\right \}\ [\text{due to Markov's inequality}]
\end{align}
Recall the definition of $\xi_1^\gamma$ and $\xi_2^\gamma$ in \eqref{}. Let $W(X_{1k})$ denote the random variable $E[\gamma(|X_{1k}-X_{2k}|^2)\mid X_{1k}]$ for $k\in S_n.$ Then, we have
\begin{align}%\label{nref16}
    &\ \left (\log\ s_n\right )^\frac{2\alpha^\prime_0}{\beta}Var[\xi_1^\gamma(\bX_1)]\nonumber \\
    =&\ \left (\log\ s_n\right )^\frac{2\alpha^\prime_0}{\beta}Var\left [\frac{1}{s_n}\sum\limits_{k\in S_n} W(X_{1k})\right ]\nonumber \\
    \leq & \frac{\left (\log\ s_n\right )^\frac{2\alpha^\prime_0}{\beta}}{s^2_n}\left \{\sum\limits_{k\in S_n}E\left [\{W(X_{1k})\}^2\right ] +\mathop{\sum\sum}\limits_{k,k^\prime\in S_n; k\neq k^\prime}\rm{Cov}(W(X_{1k}),W(X_{1k^\prime}))\right\}\nonumber \\
    \leq & \frac{\left (\log\ s_n\right )^\frac{2\alpha^\prime_0}{\beta}}{s^2_n}\sum\limits_{k\in S_n}E\left [\{W(X_{1k})\}^2\right ]\nonumber \\ &\hspace{1cm}+\frac{\left (\log\ s_n\right )^\frac{2\alpha^\prime_0}{\beta}}{s^2_n}\left\{\mathop{\sum\sum}\limits_{k,k^\prime\in S_n; k\neq k^\prime}\Corr(W(X_{1k}),W(X_{1k^\prime}))\sqrt{E\left [\{W(X_{1k})\}^2\right ]E\left [\{W(X_{1k^\prime})\}^2\right ]}\right \}\nonumber \\
    \leq & \frac{\left (\log\ s_n\right )^\frac{2\alpha^\prime_0}{\beta}}{s_n}C+\frac{\left (\log\ s_n\right )^\frac{2\alpha^\prime_0}{\beta}}{s^2_n}C\left\{\mathop{\sum\sum}\limits_{k,k^\prime\in S_n; k\neq k^\prime}\Corr{(W(X_{1k}),W(X_{1k^\prime}))}\right \}\ [\text{due to A3}].
\end{align}
The first term in the R.H.S. of the above inequality is clearly $o(1)$ for all $0<\alpha^\prime_0=\max\{\alpha_0,\alpha_3,\alpha_4\}<(1-\beta)/2$ and $0<\beta <1.$ The second term is also $o(1)$ due to A4. Hence, $\left (\log\ s_n\right )^\frac{2\alpha^\prime_0}{\beta}Var[\xi_1^\gamma(\bX_1)]\to 0$ as $n\to\infty.$\newline

\noindent Let $W^\prime(X_{1k})$ denote the random variable $E[\gamma(|Y_{1k}-X_{1k}|^2)\mid X_{1k}]$ for $k\in S_n.$ Therefore, following similar arguments, we can show that $$\left (\log\ s_n\right )^\frac{2\alpha^\prime_0}{\beta}Var\left [\sum_{k\in S_n}W^\prime_{k}/s_n\right ] = \left (\log\ s_n\right )^\frac{2\alpha^\prime_0}{\beta}Var[\xi_2^\gamma(\bX_1)]\to 0\text{ as }n\to\infty.$$ As a result, \ref{P0_1} implies that $P\left [|\xi^\gamma(\bX_1)-E[\xi^\gamma(\bX_1)]|\geq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\to 0$ as $n\to\infty.$ Now,
\begin{align*}
P\left [|\xi^\gamma(\bX_1)-E[\xi^\gamma(\bX_1)]|\geq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\geq  P\left [\xi^\gamma(\bX_1)\leq E[\xi^\gamma(\bX_1)]-\left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]
\end{align*}
If A1$^\prime$ is satisfied, then $E[\xi^\gamma(\bX_1)]=\sum_{k\in S_n}\mathcal{E}_k/s_n\geq 2\left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta},$ i.e., $E[\xi^\gamma(\bX_1)]-\left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\geq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}$ for all $n\geq N.$ Therefore,
\begin{align*}
&\ P\left [|\xi^\gamma(\bX_1)-E[\xi^\gamma(\bX_1)]|\geq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\\
\geq &\  P\left [\xi^\gamma(\bX_1)\leq E[\xi^\gamma(\bX_1)]-\left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\\
\geq &\  P\left [\xi^\gamma(\bX_1)\leq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\\
\geq &\  P\left [|\xi^\gamma(\bX_1)|\leq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\text{ for all }n\geq N.
\end{align*}
Therefore, if A1$^\prime$, A3 and A4 are satisfied, then $P\left [|\xi^\gamma(\bX_1)|\leq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\to 0 $ as $n\to\infty.$ The arguments for proving $P\left [|\xi^\gamma(\bY_1)|\leq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\to 0 $ as $n\to\infty$ are similar to that presented above. First, one needs to show that $P\left [|\xi^\gamma(\bY_1)-E[\xi^\gamma(\bY_1)]|\geq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\to 0$ as $n\to\infty.$ Note that if A1$^\prime$ is satisfied, then $E[\xi^\gamma(\bY_1)]=-\sum_{k\in S_n}\mathcal{E}_k/s_n\leq -2\left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta},$ i.e., $E[\xi^\gamma(\bY_1)]-\left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\geq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}$ for all $n\geq N.$ Therefore,

\begin{align*}
&\ P\left [|\xi^\gamma(\bY_1)-E[\xi^\gamma(\bY_1)]|\geq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\\
\geq &\  P\left [\xi^\gamma(\bY_1)\leq E[\xi^\gamma(\bY_1)]-\left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\\
\geq &\  P\left [\xi^\gamma(\bY_1)\leq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\\
\geq &\  P\left [|\xi^\gamma(\bY_1)|\leq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\text{ for all }n\geq N.
\end{align*}
Therefore, if A1$^\prime$, A3 and A4 are satisfied, then $P\left [|\xi^\gamma(\bX_1)|\leq \left (\frac{M_1}{\log\ s_n}\right )^\frac{\alpha^\prime_0}{\beta}\right ]\to 0 $ as $n\to\infty.$ Hence, $P[|\xi^\gamma(\bZ)|<n^{-\alpha^\prime_0}]\to 0$ as $s_n\to \infty.$\hfill\QEDB\newline
\begin{lemma}\label{Delta0_conv}
    If A1$^\prime$, A3 and A4 are satisfied, then $\Delta_0\to 0$ as $n\to\infty.$
\end{lemma}

\noindent {\bf Proof :} Recall that $\Delta_0$ is defined in \eqref{Delta0def} as
\begin{align*}
    \Delta_0 =  \pi_1 P[\xi^{\gamma}_{1}(\bX_1)\geq \xi^{\gamma}_{2}(\bX_1)] + \pi_2 P[\xi^{\gamma}_{1}(\bY_1)<\xi^{\gamma}_{2}(\bY_1)]
\end{align*}
Observe that $E[\xi^{\gamma}_{2}(\bX_1)-\xi^{\gamma}_{1}(\bX_1)] = \sum_{k\in S_n}\mathcal{E}_k/s_n.$ Since A1$^\prime$ is satisfied, $E\left [\xi^{\gamma}_{2}(\bX_1)- \xi^{\gamma}_{1}(\bX_1)\right ]=\sum_{k\in S_n}\mathcal{E}_k/s_n>2M_1(\log \ s_n)^{\frac{\alpha^\prime_0}{\beta}}$ for all $n\geq N.$ Therefore,
\begin{align}\label{mref14}
    &\ P[\xi^{\gamma}_{1}(\bX_1)- \xi^{\gamma}_{2}(\bX_1)\geq 0]\nonumber \\
    \leq &\ P\left [\xi^{\gamma}_{1}(\bX_1)- \xi^{\gamma}_{2}(\bX_1)> -\frac{1}{s_n}{\sum_{k\in S_n}\mathcal{E}_k}+2M_1(\log \ s_n)^{-\frac{\alpha^\prime_0}{\beta}}\right ]\nonumber \\
    \leq &\ P\left [\xi^{\gamma}_{1}(\bX_1)- \xi^{\gamma}_{2}(\bX_1)+\frac{1}{s_n}{\sum_{k\in S_n}\mathcal{E}_k}> 2M_1(\log \ s_n)^{-\frac{\alpha^\prime_0}{\beta}}\right ]\nonumber \\
    \leq &\ P\left [\left |\xi^{\gamma}_{1}(\bX_1)- \xi^{\gamma}_{2}(\bX_1)+\frac{1}{s_n}{\sum_{k\in S_n}\mathcal{E}_k}\right |> 2M_1(\log \ s_n)^{-\frac{\alpha^\prime_0}{\beta}}\right ]\nonumber \\
    =&\ P\left [\left |\xi^{\gamma}(\bX_1)-E[\xi^{\gamma}(\bX_1)]\right |> 2M_1(\log \ s_n)^{-\frac{\alpha^\prime_0}{\beta}}\right ]\text{ for all }n\geq N.
\end{align}
We have already shown in the proof of Lemma \ref{P0_conv}
that if A3 and A4 are satisfied, then $P\left [\left |\xi^{\gamma}(\bX_1)-E[\xi^{\gamma}(\bX_1)]\right |> 2M_1(\log \ s_n)^{-\frac{\alpha^\prime_0}{\beta}}\right ]\to 0$ as $n\to\infty.$  The arguments for proving $P[\xi^{\gamma}_{1}(\bY_1)- \xi^{\gamma}_{2}(\bY_1)< 0]\to 0$ as $n\to\infty$ is similar and not presented here. It can be concluded from \eqref{Delta0def} that $\Delta_0\to 0$ as $n\to\infty.$\hfill\QEDB

\section*{SIMULATION DETAILS}
\begin{itemize}
 \item GLMNET: The {\tt R}-package {\tt glmnet} is used for the implementation of GLMNET. The tuning parameter $\alpha$ in the elastic-net penalty term is kept fixed at the default value 1. The weight $\lambda$ of the penalty term is chosen by cross-validation using the function {\tt cv.glmnet} with default values of its arguments.
 \item 1NN: The {\tt knn1} function from the {\tt R}-package {\tt class} is used for implementation of the usual 1-nearest neighbor classifier.
 \item NN-RAND: The function {\tt classify} from the package {\tt RandPro} is used with default values of the arguments.
 \item NNET: For NNET, we used {\tt nnet} from the package {\tt nnet} to fit a single-hidden-layer neural network with default parameters. The number of units in the hidden layer was allowed to vary in the set $\{1,3,5,10\}$, and the minimum misclassification rate was reported as NNET.
 \item SVM: The {\tt R} package {\tt e1071} is used for implementing SVM with linear and RBF kernel. For the RBF kernel, i.e., $K_\theta(\bx,\by)=\mathrm{exp}\{-\theta\|\bx-\by\|^2\}$, we took the default value of the tuning parameter $\theta$, i.e., $\theta=1/p$.
\end{itemize}
\begin{table}[H]
\caption{Estimates of $\bar{\tau}_p(1,1),\bar{\tau}_p(1,2)$ and $\bar{\tau}_p(2,2)$ in the simulated examples (along with the standard errors in parentheses)based on 100 replications.}\label{tab3}
\small
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
% \\[-1em]
\textbf{Ex}  &$\bar{T}_{11}$& $\bar{T}_{12}$&$\bar{T}_{22}$&$\bar{T}_{12}\geq \min\{\bar{T}_{11},\bar{T}_{22}\}$\\
\hline
1 & 0.1562 & 0.1446 & 0.1273 & True \\
    & (0.0019) & (0.0020) & (0.0022)& \\ \hline
2 & 0.0909 & 0.0984 & 0.1109& True \\
    & (0.0014) & (0.0010) & (0.0015)& \\ \hline
3 & 0.0857 & 0.0821 & 0.1018 & False\\
    & (0.0018) & (0.0016) & (0.0027)& \\ \hline
4 & 0.0857 & 0.0748 & 0.0545 & True\\
    & (0.0018) & (0.0016) & (0.0016)& \\ \hline
5 & 0.2077 & 0.2106 & 0.2136 & True\\
    & (0.0005) & (0.0004) & (0.0004)& \\ \hline
\end{tabular}
%\end{center}
\end{table}
If $\bar{T}_{12}\geq \min\{\bar{T}_{11},\bar{T}_{22}\}$, then we expect $\delta_2$ to yield better misclassification rates than $\delta_1$. We have observed this while studying the performance of the proposed classifiers in the simulated examples (see Figure 3 of the main article).
\begin{table}[H]
\caption{Average time (in seconds) taken by the classifiers to classify 100+100 test observations in Example 1}\label{tab4}
\centering
%\small
\begin{adjustbox}{width=\columnwidth,center}
\begin{tabular}{|c|c|c|c|c|c|c|cccc|c|c|}
\hline
$p$ &  $\delta_0$&$\delta_1$& $\delta_2$& GLM & 1NN & NN & \multicolumn{4}{c|}{NNET$^*$} & SVM & SVM\\
 & & & & NET & & RAND & 1&3&5&10 & LIN & RBF\\
\hline
50         & 0.0149  & 0.0189  & 0.0188  & 0.094  & 0.0008 & 2.7834   & 0.009    & 0.0162  & 0.0328   & 0.111    & 0.0052   & 0.006    \\ \hline
100        & 0.0156  & 0.0236  & 0.0238  & 0.0978 & 0.0024 & 3.4872   & 0.013    & 0.0454  & 0.107    & 0.4012   & 0.0104   & 0.0102   \\ \hline
250        & 0.0185  & 0.039   & 0.0389  & 0.105  & 0.0048 & 4.6608   & 0.0382   & 0.2232  & 0.5982   & 4.2194   & 0.0224   & 0.024    \\ \hline
500        & 0.0209  & 0.0551  & 0.0549  & 0.1132 & 0.007  & 5.3308   & 0.1104   & 0.8512  & 3.924    & 19.7896  & 0.0398   & 0.0402   \\ \hline
1000       & 0.0263  & 0.0807  & 0.0808  & 0.153  & 0.012  & 6.7963 & 0.3883 & 6.3370   & 19.1236 & 100.7417 & 0.0713 & 0.0797 \\ \hline
\end{tabular}
\end{adjustbox}
\end{table}
\vspace{-0.5cm}\footnotesize{$^*$ 1,3,5,10 represent the numbers of units in the single-hidden-layer of the neural network.}

Note that the weight $\lambda$ of the elastic-net penalty in GLMNET is tuned using cross-validation method. The rest of the existing classifiers in Table \ref{tab4} are implemented with their respective default arguments. The proposed classifiers are free from parameter tuning. \newline

\noindent {\bf Codes}: {\bl The {\tt R}-codes for implementation of the proposed classifiers are uploaded along with the supplementary material as `RCodes.zip'.}
\vfill
\bibliography{citation}
\end{document}
